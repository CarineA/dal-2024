[
  {
    "objectID": "tutorials/tutorial-w06.html",
    "href": "tutorials/tutorial-w06.html",
    "title": "DAL tutorial - Week 6",
    "section": "",
    "text": "During the lecture, we have learnt two types of measures.\n\n\n\n\n\n\nSummary measures\n\n\n\nMeasures of central tendency (mean, median, mode) indicate the typical or central value of a sample.\nMeasures of dispersion (min-max, range, standard deviation) indicate the dispersion of the sample values around the central tendency value.\n\n\nWhen you work with data, you always want to get summary measures for most of the variables in the data.\nData reports usually include summary measures. It is also important to understand which summary measure is appropriate for which type of variable.\nWe have covered this in the lecture, so we won’t go over it again here. Instead, you will learn how to obtain summary measures using the summarise() function from the dplyr tidyverse package.\nsummarise() takes at least two arguments:\n\nThe data frame to summarise.\nOne or more summary functions.\n\nFor example, let’s get the mean the reaction time column RT. Easy! (First attach the tidyverse and read the song2020/shallow.csv file into a variable called shallow.)\n\nsummarise(shallow, RT_mean = mean(RT))\n\nGreat! The mean reaction times of the entire sample is 867.3592 ms.\nYou can round numbers with the round() function. For example:\n\nnum &lt;- 867.3592\nround(num)\nround(num, 1)\nround(num, 2)\n\nThe second argument sets the number of decimals to round to (by default, it is 0, so the number is rounded to the nearest integer).\nLet’s recalculate the mean by rounding it this time.\n\nsummarise(shallow, RT_mean = round(mean(RT)))\n\nWhat if we want also the standard deviation? Easy: we use the sd() function. (Round the mean and SD with the round() function in your code).\n\n# round the mean and SD\nsummarise(shallow, RT_mean = mean(RT), RT_sd = sd(RT))\n\nNow we know that reaction times are on average 867 ms long and have a standard deviation of about 293 ms (rounded to the nearest integer).\nLet’s go all the way and also get the minimum and maximum RT values with the min() and max() functions (round all the summary measures).\n\nsummarise(\n  shallow,\n  RT_mean = mean(RT), RT_sd = sd(RT),\n  RT_min = ..., RT_max = ...\n)\n\nFab! When writing a data report, you could write something like this.\n\nReaction times are on average 867 ms long (SD = 293 ms), with values ranging from 0 to 1994 ms.\n\nWe won’t go into the details of what standard deviations are, but you can just think of them as a relative measure of how dispersed the data are around the mean: the higher the SD, the greater the dispersion around the mean, i.e. the greater the variability in the data.\nWhen required, you can use the median() function to calculate the median, instead of the mean(). Go ahead and calculate the median reaction times in the data. Is it similar to the mean?\n\n\nMost base R functions behave unexpectedly if the vector they are used on contain NA values.\nNA is a special object in R, that indicates that a value is Not Available, meaning that that observation does not have a value.\nFor example, in the following numeric vector, there are 5 objects:\n\na &lt;- c(3, 5, 3, NA, 4)\n\nFour are numbers and one is NA.\nIf you calculate the mean of a with mean() something strange happens.\n\nmean(a)\n\nThe functions returns NA.\nThis is because by default when just one value in the vector is NA then operations on the vector will return NA.\n\nmean(a)\nsum(a)\nsd(a)\n\nIf you want to discard the NA values when operating on a vector that contains them, you have to set the na.rm (for “NA remove”) argument to TRUE.\n\nmean(a, na.rm = TRUE)\nsum(a, na.rm = TRUE)\nsd(a, na.rm = TRUE)\n\n\n\n\n\n\n\nQuiz 1\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nCheck the documentation of ?mean.\n\n\n\n\n\nNote that R has a mode() function, but alas this is not the statistical mode. To get the mode of a categorical variable you can just count the occurrences of the values of that variable and the value that occurs the most is the mode!\nYou will learn how to count occurrences below. But first, let’s see what density plots are!"
  },
  {
    "objectID": "tutorials/tutorial-w06.html#summary-measures",
    "href": "tutorials/tutorial-w06.html#summary-measures",
    "title": "DAL tutorial - Week 6",
    "section": "",
    "text": "During the lecture, we have learnt two types of measures.\n\n\n\n\n\n\nSummary measures\n\n\n\nMeasures of central tendency (mean, median, mode) indicate the typical or central value of a sample.\nMeasures of dispersion (min-max, range, standard deviation) indicate the dispersion of the sample values around the central tendency value.\n\n\nWhen you work with data, you always want to get summary measures for most of the variables in the data.\nData reports usually include summary measures. It is also important to understand which summary measure is appropriate for which type of variable.\nWe have covered this in the lecture, so we won’t go over it again here. Instead, you will learn how to obtain summary measures using the summarise() function from the dplyr tidyverse package.\nsummarise() takes at least two arguments:\n\nThe data frame to summarise.\nOne or more summary functions.\n\nFor example, let’s get the mean the reaction time column RT. Easy! (First attach the tidyverse and read the song2020/shallow.csv file into a variable called shallow.)\n\nsummarise(shallow, RT_mean = mean(RT))\n\nGreat! The mean reaction times of the entire sample is 867.3592 ms.\nYou can round numbers with the round() function. For example:\n\nnum &lt;- 867.3592\nround(num)\nround(num, 1)\nround(num, 2)\n\nThe second argument sets the number of decimals to round to (by default, it is 0, so the number is rounded to the nearest integer).\nLet’s recalculate the mean by rounding it this time.\n\nsummarise(shallow, RT_mean = round(mean(RT)))\n\nWhat if we want also the standard deviation? Easy: we use the sd() function. (Round the mean and SD with the round() function in your code).\n\n# round the mean and SD\nsummarise(shallow, RT_mean = mean(RT), RT_sd = sd(RT))\n\nNow we know that reaction times are on average 867 ms long and have a standard deviation of about 293 ms (rounded to the nearest integer).\nLet’s go all the way and also get the minimum and maximum RT values with the min() and max() functions (round all the summary measures).\n\nsummarise(\n  shallow,\n  RT_mean = mean(RT), RT_sd = sd(RT),\n  RT_min = ..., RT_max = ...\n)\n\nFab! When writing a data report, you could write something like this.\n\nReaction times are on average 867 ms long (SD = 293 ms), with values ranging from 0 to 1994 ms.\n\nWe won’t go into the details of what standard deviations are, but you can just think of them as a relative measure of how dispersed the data are around the mean: the higher the SD, the greater the dispersion around the mean, i.e. the greater the variability in the data.\nWhen required, you can use the median() function to calculate the median, instead of the mean(). Go ahead and calculate the median reaction times in the data. Is it similar to the mean?\n\n\nMost base R functions behave unexpectedly if the vector they are used on contain NA values.\nNA is a special object in R, that indicates that a value is Not Available, meaning that that observation does not have a value.\nFor example, in the following numeric vector, there are 5 objects:\n\na &lt;- c(3, 5, 3, NA, 4)\n\nFour are numbers and one is NA.\nIf you calculate the mean of a with mean() something strange happens.\n\nmean(a)\n\nThe functions returns NA.\nThis is because by default when just one value in the vector is NA then operations on the vector will return NA.\n\nmean(a)\nsum(a)\nsd(a)\n\nIf you want to discard the NA values when operating on a vector that contains them, you have to set the na.rm (for “NA remove”) argument to TRUE.\n\nmean(a, na.rm = TRUE)\nsum(a, na.rm = TRUE)\nsd(a, na.rm = TRUE)\n\n\n\n\n\n\n\nQuiz 1\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nCheck the documentation of ?mean.\n\n\n\n\n\nNote that R has a mode() function, but alas this is not the statistical mode. To get the mode of a categorical variable you can just count the occurrences of the values of that variable and the value that occurs the most is the mode!\nYou will learn how to count occurrences below. But first, let’s see what density plots are!"
  },
  {
    "objectID": "tutorials/tutorial-w06.html#density-plots",
    "href": "tutorials/tutorial-w06.html#density-plots",
    "title": "DAL tutorial - Week 6",
    "section": "2 Density plots",
    "text": "2 Density plots\n\n\n\n\n\n\nDensity plots\n\n\n\nDensity plots show the distribution (i.e. the “probability density”) of the values of a continuous variable.\nThey are created with geom_density().\n\n\nReaction times is a numeric continuous variable so density plots are appropriate.\nTo plot the probability density of a continuous variable, you can use the density geometry.\n\nshallow |&gt;\n  ggplot(aes(x = RT)) +\n  geom_density()\n\nThe black solid curve in the plot indicates the density of the data (the y-axis) along the values of RT (the x-axis).\nThe higher the point of the curve is on the y-axis (i.e. the higher the density), the more data there is at the corresponding x-axis value.\nFor example, the highest point in the curve is at around 750 ms (the white vertical line between 500 and 1000 is 750).\nThis means that around 750 ms there are many observations.\nOn the other hand, if you look at the curve to the left of 500 ms RT and above 1500 ms RT, the height of the points forming the curve are much lower and in some cases they even go to 0 density (y-axis).\nNote that to create a density plot, you only need to specify the x-axis. The y-axis is the probability density, which is automatically calculated (a bit like counts in bar charts, remember?).\n\n2.1 Make things cosy with a rug\nThe density line shows you a smoothed representation of the data distribution over RT values, but you might also want to see the raw data represented on the xsxis.\nYou can do so by adding the rug geometry. Go ahead and add a rug…\n\nshallow |&gt;\n  ggplot(aes(RT)) +\n  geom_density() +\n  ...\n\nYou should get the following:\nNice huh? You can also change the opacity of the ticks of the rug to have a better sense of how many ticks there are at certain values on the x-axis.\nOpacity of geometries can be adjusted with the alpha argument: 0 means completely transparent and 1 means completely opaque.\nLet’s set the alpha of the rug geometry to 0.1.\nCan you see how the blackest parts of the rug correspond to the higher parts of the density curve?\n\n\n\n\n\n\nRug\n\n\n\nRaw data can be shown with a rug, i.e. ticks on the axes that mark where the data is.\nYou can add a rug with geom_rug().\n\n\n\n\n\n\n\n\nQuiz 2\n\n\n\nWhat can you notice about the distribution of RT values?\n\n\n\n\n\n\nHint\n\n\n\n\n\nIs the distribution symmetric around the highest density point?\n\n\n\n\n\nKeep reading to learn how to count occurrences."
  },
  {
    "objectID": "tutorials/tutorial-w06.html#count-occurrences",
    "href": "tutorials/tutorial-w06.html#count-occurrences",
    "title": "DAL tutorial - Week 6",
    "section": "3 Count occurrences",
    "text": "3 Count occurrences\nOften, you need to count occurrences in the data frame based on the values of specific columns.\nFor example, let’s count the number of correct and incorrect trials in the shallow data frame.\nThe column ACC tells us whether a trial is incorrect 0 or correct 1. (We will see how this way of coding binary variables, with 0s and 1s is not an ideal, although very common way, of coding binary variables. For now let’s keep it as is.)\nWe can use the count() function from the dplyr tidyverse package to count the number of occurrences for each value of a specific column.\nThe function count() takes the name of a tibble and the name of the column you want to count values in.\n\ncount(shallow, ACC)\n\n# You can also write that as\n# shallow |&gt; count(ACC)\n\nHow many correct trials are there in the shallow tibble? And how many incorrect trials?\nNote that you can add multiple column names, separated by commas, to get counts for the combinations of values of each column.\nTry to get counts of the combination of ACC and Group (L1 vs L2 participants). Replace ... with the right code.\n\ncount(shallow, ...)\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nIn count(), include the names of the two columns you want to get counts of, separated by commas.\n\n\n\nThis is the output:\nAre there differences in accuracy between the L1 and L2 group? It’s difficult to say just by looking at those numbers, because the total number of trials for L1 and L2 participants is different.\nThere are more L2 trials than L1 trials in the data set.\nWhen the total number of observations is not the same in the groups we are trying to compare, we can calculate the proportion instead of the raw count.\nThis should ring a bell. Do you remember position = \"fill\" in bar charts? This is based on the same reasoning.\nWe can calculate the proportion of correct and incorrect trials using a chain of functions.\n\nshallow |&gt;\n  add_count(Group, name = \"tot\") |&gt;\n  count(Group, ACC, tot) |&gt;\n  mutate(\n    prop = round(n / tot, 2)\n  )\n\nTo learn what each line does, you can split the chain in multiple steps and inspect each step.\n\nshallow_tot &lt;- shallow |&gt;\n  add_count(Group, name = \"tot\")\n\nshallow_count &lt;- shallow_tot |&gt;\n  count(Group, ACC, tot) \n\nshallow_prop &lt;- shallow_count |&gt;\n  mutate(\n    # round proportion to 2 decimals.\n    prop = round(n / tot, 2)\n  )\n\nNow check shallow_tot, shallow_count and shallow_prop.\nBased on the proportion of correct trials in the L1 and L2 group, are there substantial differences in how the two groups performed? Or are they similar? If not, who was better?"
  },
  {
    "objectID": "tutorials/tutorial-w06.html#grouping-data",
    "href": "tutorials/tutorial-w06.html#grouping-data",
    "title": "DAL tutorial - Week 6",
    "section": "4 Grouping data",
    "text": "4 Grouping data\nSometimes you might want to get summary measures for one column depending on different values of another column.\nYou can use the group_by() function from the dplyr tidyverse package, together with summarise() to achieve that. Let’s see how it works.\n\ngroup_by(shallow, Group) |&gt;\n  summarise(\n    RT_mean = round(mean(RT)),\n    RT_sd = round(sd(RT))\n  )\n\nThe group_by() function takes at least two arguments:\n\nThe name of the tibble to group.\nThe name of the columns to group the tibble by, separated by commas.\n\nHere we are grouping shallow by Group.\nIn fact, you can even use a pipe for the tibble of group_by() as we have done for other functions, like so:\n\nshallow |&gt;\n  group_by(Group) |&gt;\n    summarise(\n      RT_mean = round(mean(RT)),\n      RT_sd = round(sd(RT))\n    )\n\n\n\n\n\n\n\nQuiz 3"
  },
  {
    "objectID": "tutorials/tutorial-w06.html#practice",
    "href": "tutorials/tutorial-w06.html#practice",
    "title": "DAL tutorial - Week 6",
    "section": "5 Practice",
    "text": "5 Practice\n\n\n\n\n\n\nPractice 1\n\n\n\n\nRead the cameron2020/gestures.csv file in R.\nCalculate the following:\n\nMeasure of central tendency and dispersion for the count column (it contains the number of gestures performed by each child in different tasks).\nMeasure of central tendency and dispersion for the count column grouped by month (the child’s age).\nTotal number of gestures by children (dyad).\nNumber of children by background.\n\nWrite a short paragraph where you report the measures.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nTo calculate the total number of gestures by children, you need the sum() function.\nTo calculate the number of children by background, you need the distinct() function.\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nHave you tried doing the exercise and couldn’t work it out?\nThe you can check the code solution here…\n\n\n\n\n\n\nCode\n\n\n\n\n\ngestures |&gt;\n  summarise(\n    count_med = median(count, na.rm = TRUE),\n    count_min = min(count, na.rm = TRUE),\n    count_max = max(count, na.rm = TRUE),\n    count_range = count_max - count_min\n  )\n\ngestures |&gt;\n  group_by(months) |&gt;\n  summarise(\n    count_med = median(count, na.rm = TRUE),\n    count_min = min(count, na.rm = TRUE),\n    count_max = max(count, na.rm = TRUE),\n    count_range = count_max - count_min\n  )\n\ngestures |&gt;\n  group_by(dyad) |&gt;\n  summarise(\n    count_tot = sum(count)\n  )\n\ngestures |&gt;\n  distinct(background, dyad) |&gt;\n  count(background)"
  },
  {
    "objectID": "tutorials/tutorial-w06.html#summary",
    "href": "tutorials/tutorial-w06.html#summary",
    "title": "DAL tutorial - Week 6",
    "section": "6 Summary",
    "text": "6 Summary\n\n\n\n\n\n\nData summaries\n\nsummarise() allows you to calculate measures of central tendency and dispersion (with mean(), median(), min() and max(), sd(), …).\ncount() lets you count the number of occurrences of levels in a categorical variable.\ngroup_by() allows you to group a tibble according to one or more variables.\n\nPlotting\n\ngeom_density() creates density plots of continuous variables.\ngeom_rug() adds raw data as ticks on the x-axis of density plots."
  },
  {
    "objectID": "tutorials/tutorial-w04.html",
    "href": "tutorials/tutorial-w04.html",
    "title": "QML tutorial - Week 4",
    "section": "",
    "text": "Last week, you learnt how to use R scripts to save your code.\nKeeping track of the code you use for data analysis is a very important aspect of research project managing: not only the code is there if you need to rerun it later, but it allows your data analysis to be reproducible (i.e., it can be reproduced by you or other people in such a way that starting with the same data and code you get to the same results).\n\n\n\n\n\n\nReproducible research\n\n\n\nResearch is reproducible when the same data and same code return the same results.\n\n\nR scripts are great for writing code, and you can even document the code (add explanations or notes) with comments (i.e. lines that start with #).\nBut for longer text or complex data analysis reports, R scripts can be a bit cumbersome.\nA solution to this is using Quarto files (they have the .qmd extension).\n\n\n\n\n\n\nQuiz 1\n\n\n\n**When is research not reproducible?\n\n a. When the results do not match the researcher's expectations. b. When the the same data and code as in the original study do not produce the published results. c. When research conducted by a different research team with new data does not produce the results as published in the original study. \n\n\n\n\n\n\n\nHint\n\n\n\n\n\nResearch is reproducible when you can produce the same results using the original data and code/methods.\nResearch is replicable when you can produce the same results using new data and the original code/methods.\nSee https://the-turing-way.netlify.app/reproducible-research/overview/overview-definitions.html#table-of-definitions-for-reproducibility.\n\n\n\n\n\n\n\nQuarto is a file format that allows you to mix code and formatted text in the same file.\nThis means that you can write dynamic reports using Quarto files: dynamic reports are just like analysis reports (i.e. they include formatted text, plots, tables, code output, code, etc…) but they are dynamic in the sense that if, for example, data or code changes, you can just rerun the report Rmd file and all code output (plots, tables, etc…) is updated accordingly!\n\n\n\n\n\n\nDynamic reports in Quarto\n\n\n\nQuarto is a file type with extension .Rmd in which you can write formatted text and code together.\nQuarto can be used to generate dynamic reports: these are files that are generated automatically from the file source, ensuring data and results in the report are always up to date.\n\n\n\n\n\nR comments in R scripts cannot be formatted (for example, you can’t make bold or italic texts).\nText in Quarto files can be fully formatted using a simple but powerful mark-up language called markdown.\nYou don’t have to learn markdown all in one go, so I encourage you to just learn it bit by bit, at your pace. You can look at the the Markdown Guide for an in-depth intro and/or dive in the Markdown Tutorial for a hands-on approach.\nA few quick pointers (you can test them in the Markdown Live Preview):\n\nText can be made italics by enclosing it between single stars: *this text is in italics*.\nYou can make text bold with two stars: **this text is bold!**.\nHeadings are created with #: # This is a level-1 heading. ## This is a level-2 heading.\n\n\n\n\n\n\n\nMark-up, Markdown\n\n\n\nA mark-up language is a text-formatting system consisting of symbols or keywords that control the structure, formatting or relationships of textual elements. The most common mark-up languages are HTML, XML and TeX.\nMarkdown is a simple yet powerful mark-up language.\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen working through these tutorials, always make sure you are in the course Quarto Project you just created.\nYou know you are in a Quarto Project because you can see the name of the Project in the top-right corner of RStudio, next to the light-blue cube icon.\nIf you see Project (none) in the top-right corner, that means you are not in the Quarto Project.\nTo make sure you are in the Quarto project, you can open the project by going to the project folder in File Explorer (Win) or Finder (macOS) and double click on the .Rproj file.\n\n\nTo create a new .qmd file, just click on the New file button, then Quarto Document.... (If you are asked to install/update packages, do so.)\n\n\n\n\n\nA window will open. Add a title of your choice and your name. Make sure the Use visual markdown editor is NOT ticked, then click OK (you will be free to use the visual editor later, but it is important that you first see what a Quarto document looks like under the hood first).\n\n\n\n\n\nA new .qmd file will be created and will open in the File Editor panel in RStudio.\nNote that creating a Quarto file does not automatically saves it on your computer. To do so, either use the keyboard short-cut CMD+S/CTRL+S or click on the floppy disk icon in the menu below the file tab.\n\n\n\n\n\nSave the file inside the code/ folder with the following name: tutorial-w04.qmd.\nRemember that all the files of your RStudio project don’t live inside RStudio but on your computer.\n\n\n\nA Quarto file usually has three main parts:\n\nThe YAML header (green).\nCode chunks (red).\nText (blue).\n\n\n\n\n\n\nEach Quarto file has to start with a YAML header, but you can include as many code chunks and as much text as you wish, in any order.\n\n\n\n\n\n\nQuarto: YAML header\n\n\n\nThe header of a .qmd file contains a list of key: value pairs, used to specify settings or document info like the title and author.\nYAML headers start and end with three dashes ---.\n\n\n\n\n\n\n\n\nQuarto: Code chunks\n\n\n\nCode chunks start and end with three back-ticks ``` and they contain code.\n{r} indicates that the code is R code. Settings can be specified inside the chunk with the #| prefix: for example #| label: setup sets the name of the chunk (the label) to setup.\n\n\n\n\n\nWhen using Quarto projects, the working directory (the directory all relative paths are relative to) is the project folder.\nHowever, when running code from a Quarto file, the code is run as if the working directory were the folder in which the file is saved.\nThis isn’t an issue if the Quarto file is directly in the project folder, but in our case our Quarto files live in the code/ folder within the project folder (and it is good practice to do so!).\nWe can instruct R to always run code from the project folder (i.e. the working directory is the project folder). This is when the _quarto.yml file comes into play.\nOpen the _quarto.yml file in RStudio (you can simply click on the file in the Files tab and that will open the file in the RStudio editor). Add the line execute-dir: project under the title. Note that indentation should be respected, so the line you write should align with title:, not with project:.\nproject:\n  title: \"dal\"\n  execute-dir: project\nNow, all code in Quarto files, no matter where they are saved, will be run with the project folder as the working directory.\n\n\n\nYou will use the Quarto document you created to write text and code for this tutorial.\nThis is what the Quarto document should look like now:\n\n\n\n\n\nNow add an empty line and in the following line write a second-level heading ## Attach packages, followed by two empty lines. Like so:\n\n\n\n\n\nNow we can insert a code chunk to add the code to attach the tidyverse. To insert a new code chunk, you can click on the Insert a new code chunk button (the little green square icon with a C and a plus) , or you can press OPT+CMD+I/ALT+CTRL+I.\n\n\n\n\n\nA new R code chunk will be inserted at the text cursor position.\nNow go ahead and add the following lines of code inside the R code chunk.\n#| label: setup\n\nlibrary(tidyverse)\n\n\n\n\n\n\nRunning code in Quarto documents\n\n\n\nTo run the code, you have two options:\n\nYou click the small green triangle in the top-right corner of the chunk. This runs all the code in the code chunk.\nEnsure the text cursor is inside the code chunk and press SHIFT+CMD+ENTER/SHIFT+CTRL+ENTER. This too runs all the code in the code chunk.\n\nIf you want to run line by line in the code chunk, you can place the text cursor on the line you want to run and press CMD+ENTER/CTRL+ENTER. The current line is run nd the text cursor is moved to the next line.\n\n\nRun the setup chunk now.\n\n\n\n\n\nYou will see messages printed below the code chunk, in your Quarto file (don’t worry about the Conflicts, they just tell you that some functions from the tidyverse packages have replaced the base R functions, which is OK).\n\n\n\n\n\n\nPractice 1\n\n\n\nTry this yourself:\n\nCreate a new second-level heading (with ##) called Read data.\nCreate a new R code chunk.\nSet the label of the chunk to read-data.\nAdd code to read the following files:\n\nwinter202/polite.csv\ncoretta2022/glot_status.rds\n\nRun the code.\n\n\n\n\n\n\nYou can render a .qmd file into a nicely formatted HTML file.\nTo render a Quarto file, just click on the Render button and an HTML file will be created and saved in the same location of the Quarto file.\n\n\n\n\n\nIt will also be shown in the Viewer pane (like in the picture below) or in a new window (you can set this option in the RStudio Preferences &gt; R Markdown &gt; Basics &gt; Show output preview in…).\n\n\n\n\n\nRendering Quarto files is not restricted to HTML, but also PDFs and even Word documents!\nThis is very handy when you are writing an analysis report you need to share with others.\n\n\n\n\n\n\nQuarto: Rendering\n\n\n\nQuarto files can be rendered into other formats, like HTML, PDF and Word documents.\n\n\nThe assessments of this course will require you to write text and code in a Quarto file and render it to PDF.\nYou could even write your dissertation in Quarto!\nThe following sections will introduce you to the basics of plotting data. You will keep learning how to create plots throughout the course."
  },
  {
    "objectID": "tutorials/tutorial-w04.html#quarto",
    "href": "tutorials/tutorial-w04.html#quarto",
    "title": "QML tutorial - Week 4",
    "section": "",
    "text": "Last week, you learnt how to use R scripts to save your code.\nKeeping track of the code you use for data analysis is a very important aspect of research project managing: not only the code is there if you need to rerun it later, but it allows your data analysis to be reproducible (i.e., it can be reproduced by you or other people in such a way that starting with the same data and code you get to the same results).\n\n\n\n\n\n\nReproducible research\n\n\n\nResearch is reproducible when the same data and same code return the same results.\n\n\nR scripts are great for writing code, and you can even document the code (add explanations or notes) with comments (i.e. lines that start with #).\nBut for longer text or complex data analysis reports, R scripts can be a bit cumbersome.\nA solution to this is using Quarto files (they have the .qmd extension).\n\n\n\n\n\n\nQuiz 1\n\n\n\n**When is research not reproducible?\n\n a. When the results do not match the researcher's expectations. b. When the the same data and code as in the original study do not produce the published results. c. When research conducted by a different research team with new data does not produce the results as published in the original study. \n\n\n\n\n\n\n\nHint\n\n\n\n\n\nResearch is reproducible when you can produce the same results using the original data and code/methods.\nResearch is replicable when you can produce the same results using new data and the original code/methods.\nSee https://the-turing-way.netlify.app/reproducible-research/overview/overview-definitions.html#table-of-definitions-for-reproducibility.\n\n\n\n\n\n\n\nQuarto is a file format that allows you to mix code and formatted text in the same file.\nThis means that you can write dynamic reports using Quarto files: dynamic reports are just like analysis reports (i.e. they include formatted text, plots, tables, code output, code, etc…) but they are dynamic in the sense that if, for example, data or code changes, you can just rerun the report Rmd file and all code output (plots, tables, etc…) is updated accordingly!\n\n\n\n\n\n\nDynamic reports in Quarto\n\n\n\nQuarto is a file type with extension .Rmd in which you can write formatted text and code together.\nQuarto can be used to generate dynamic reports: these are files that are generated automatically from the file source, ensuring data and results in the report are always up to date.\n\n\n\n\n\nR comments in R scripts cannot be formatted (for example, you can’t make bold or italic texts).\nText in Quarto files can be fully formatted using a simple but powerful mark-up language called markdown.\nYou don’t have to learn markdown all in one go, so I encourage you to just learn it bit by bit, at your pace. You can look at the the Markdown Guide for an in-depth intro and/or dive in the Markdown Tutorial for a hands-on approach.\nA few quick pointers (you can test them in the Markdown Live Preview):\n\nText can be made italics by enclosing it between single stars: *this text is in italics*.\nYou can make text bold with two stars: **this text is bold!**.\nHeadings are created with #: # This is a level-1 heading. ## This is a level-2 heading.\n\n\n\n\n\n\n\nMark-up, Markdown\n\n\n\nA mark-up language is a text-formatting system consisting of symbols or keywords that control the structure, formatting or relationships of textual elements. The most common mark-up languages are HTML, XML and TeX.\nMarkdown is a simple yet powerful mark-up language.\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen working through these tutorials, always make sure you are in the course Quarto Project you just created.\nYou know you are in a Quarto Project because you can see the name of the Project in the top-right corner of RStudio, next to the light-blue cube icon.\nIf you see Project (none) in the top-right corner, that means you are not in the Quarto Project.\nTo make sure you are in the Quarto project, you can open the project by going to the project folder in File Explorer (Win) or Finder (macOS) and double click on the .Rproj file.\n\n\nTo create a new .qmd file, just click on the New file button, then Quarto Document.... (If you are asked to install/update packages, do so.)\n\n\n\n\n\nA window will open. Add a title of your choice and your name. Make sure the Use visual markdown editor is NOT ticked, then click OK (you will be free to use the visual editor later, but it is important that you first see what a Quarto document looks like under the hood first).\n\n\n\n\n\nA new .qmd file will be created and will open in the File Editor panel in RStudio.\nNote that creating a Quarto file does not automatically saves it on your computer. To do so, either use the keyboard short-cut CMD+S/CTRL+S or click on the floppy disk icon in the menu below the file tab.\n\n\n\n\n\nSave the file inside the code/ folder with the following name: tutorial-w04.qmd.\nRemember that all the files of your RStudio project don’t live inside RStudio but on your computer.\n\n\n\nA Quarto file usually has three main parts:\n\nThe YAML header (green).\nCode chunks (red).\nText (blue).\n\n\n\n\n\n\nEach Quarto file has to start with a YAML header, but you can include as many code chunks and as much text as you wish, in any order.\n\n\n\n\n\n\nQuarto: YAML header\n\n\n\nThe header of a .qmd file contains a list of key: value pairs, used to specify settings or document info like the title and author.\nYAML headers start and end with three dashes ---.\n\n\n\n\n\n\n\n\nQuarto: Code chunks\n\n\n\nCode chunks start and end with three back-ticks ``` and they contain code.\n{r} indicates that the code is R code. Settings can be specified inside the chunk with the #| prefix: for example #| label: setup sets the name of the chunk (the label) to setup.\n\n\n\n\n\nWhen using Quarto projects, the working directory (the directory all relative paths are relative to) is the project folder.\nHowever, when running code from a Quarto file, the code is run as if the working directory were the folder in which the file is saved.\nThis isn’t an issue if the Quarto file is directly in the project folder, but in our case our Quarto files live in the code/ folder within the project folder (and it is good practice to do so!).\nWe can instruct R to always run code from the project folder (i.e. the working directory is the project folder). This is when the _quarto.yml file comes into play.\nOpen the _quarto.yml file in RStudio (you can simply click on the file in the Files tab and that will open the file in the RStudio editor). Add the line execute-dir: project under the title. Note that indentation should be respected, so the line you write should align with title:, not with project:.\nproject:\n  title: \"dal\"\n  execute-dir: project\nNow, all code in Quarto files, no matter where they are saved, will be run with the project folder as the working directory.\n\n\n\nYou will use the Quarto document you created to write text and code for this tutorial.\nThis is what the Quarto document should look like now:\n\n\n\n\n\nNow add an empty line and in the following line write a second-level heading ## Attach packages, followed by two empty lines. Like so:\n\n\n\n\n\nNow we can insert a code chunk to add the code to attach the tidyverse. To insert a new code chunk, you can click on the Insert a new code chunk button (the little green square icon with a C and a plus) , or you can press OPT+CMD+I/ALT+CTRL+I.\n\n\n\n\n\nA new R code chunk will be inserted at the text cursor position.\nNow go ahead and add the following lines of code inside the R code chunk.\n#| label: setup\n\nlibrary(tidyverse)\n\n\n\n\n\n\nRunning code in Quarto documents\n\n\n\nTo run the code, you have two options:\n\nYou click the small green triangle in the top-right corner of the chunk. This runs all the code in the code chunk.\nEnsure the text cursor is inside the code chunk and press SHIFT+CMD+ENTER/SHIFT+CTRL+ENTER. This too runs all the code in the code chunk.\n\nIf you want to run line by line in the code chunk, you can place the text cursor on the line you want to run and press CMD+ENTER/CTRL+ENTER. The current line is run nd the text cursor is moved to the next line.\n\n\nRun the setup chunk now.\n\n\n\n\n\nYou will see messages printed below the code chunk, in your Quarto file (don’t worry about the Conflicts, they just tell you that some functions from the tidyverse packages have replaced the base R functions, which is OK).\n\n\n\n\n\n\nPractice 1\n\n\n\nTry this yourself:\n\nCreate a new second-level heading (with ##) called Read data.\nCreate a new R code chunk.\nSet the label of the chunk to read-data.\nAdd code to read the following files:\n\nwinter202/polite.csv\ncoretta2022/glot_status.rds\n\nRun the code.\n\n\n\n\n\n\nYou can render a .qmd file into a nicely formatted HTML file.\nTo render a Quarto file, just click on the Render button and an HTML file will be created and saved in the same location of the Quarto file.\n\n\n\n\n\nIt will also be shown in the Viewer pane (like in the picture below) or in a new window (you can set this option in the RStudio Preferences &gt; R Markdown &gt; Basics &gt; Show output preview in…).\n\n\n\n\n\nRendering Quarto files is not restricted to HTML, but also PDFs and even Word documents!\nThis is very handy when you are writing an analysis report you need to share with others.\n\n\n\n\n\n\nQuarto: Rendering\n\n\n\nQuarto files can be rendered into other formats, like HTML, PDF and Word documents.\n\n\nThe assessments of this course will require you to write text and code in a Quarto file and render it to PDF.\nYou could even write your dissertation in Quarto!\nThe following sections will introduce you to the basics of plotting data. You will keep learning how to create plots throughout the course."
  },
  {
    "objectID": "tutorials/tutorial-w04.html#plotting-basics",
    "href": "tutorials/tutorial-w04.html#plotting-basics",
    "title": "QML tutorial - Week 4",
    "section": "2 Plotting basics",
    "text": "2 Plotting basics\nPlotting data in R is easy once you understand the basics.\n\n2.1 Graphic systems\nIn R, you can create plots using different systems.\n\nBase R.\nlattice.\nggplot2.\nmore…\n\nIn this course you will learn how to use the ggplot2 system, but before we dive in, let’s have a look at the base R plotting system too.\n\n\n2.2 Base R plotting function\nLet’s create two vectors, x and y and plot them. For now, run the following code in the Console (not in the Quarto document).\n\nx &lt;- 1:10\ny &lt;- x^3\n\nplot(x, y)\n\n\n\n\nEasy!\nNow let’s add a few more things.\n\nplot(x, y, type = \"l\", col = \"purple\", lwd = 3, lty = \"dashed\")\n\n\n\n\nWith plots as simple as this one, the base R plotting system is sufficient, but to create more complex plots (which is virtually always the case), base R gets incredibly complicated.\nInstead we can use the tidyverse package ggplot2. ggplot2 works well with the other tidyverse packages and it follows the same principles, so it is convenient to use it for data visualisation instead of base R!"
  },
  {
    "objectID": "tutorials/tutorial-w04.html#your-first-ggplot2-plot",
    "href": "tutorials/tutorial-w04.html#your-first-ggplot2-plot",
    "title": "QML tutorial - Week 4",
    "section": "3 Your first ggplot2 plot",
    "text": "3 Your first ggplot2 plot\nThe tidyverse package ggplot2 provides users with a consistent set of functions to create captivating graphics.\n\n\n\n\n\n\nWarning\n\n\n\nTo be able to use the functions in a package, you first need to attach the package. We have already attached the library(tidyverse) packages, among which there is ggplot2, so you don’t need to do anything else.\n\n\nWe will first use the polite data to learn the basics of plotting using ggplot.\nIn this tutorial we will use the following columns:\n\nf0mn: mean f0 (fundamental frequency).\nH1H2: difference between H2 and H1 (second and first harmonic). A higher H1-H2 difference indicates greater breathiness.\n\n\n3.1 A basic plot\nThese are the minimum constituents of a ggplot2 plot.\n\n\n\n\n\n\nggplot basics\n\n\n\n\nThe data: you have to specify the data frame with the data you want to plot.\nThe mapping: the mapping tells ggplot how to map data columns to parts of the plot like the axes or groupings within the data. These parts are called aesthetics, or aes for short.\n\n\n\nYou can specify the data and mapping with the data and mapping arguments of the ggplot() function.\nNote that the mapping argument is always specified with aes(): mapping = aes(…).\nIn the following bare plot, we are just mapping background to the x-axis count_tot the y-axis, from the gestures_tot data frame.\nCreate a new code chunk, copy the following code and run it. From this point on I will assume you’ll create a new code chunk and run the code yourself, without explicit instructions.\n\nggplot(\n  data = polite,\n  mapping = aes(x = f0mn, y = H1H2)\n)\n\n\n\n\nNot much to see here: just two axes!\n\n\n\n\n\n\nQuiz 2\n\n\n\nIs the following code correct? Justify your answer. TRUEFALSE\nggplot(\n  data = polite,\n  mapping = c(x = total_duration, y = articulation_rate)\n)\n\n\n\n\n3.2 Let’s add geometries\nNice, but we are missing the most important part: showing the data!\nData is represented with geometries, or geoms for short. geoms are added to the base ggplot with functions whose names all start with geom_.\n\n\n\n\n\n\nGeometries\n\n\n\nGeometries are plot elements that show the data through geometric shapes.\nDifferent geometries are added to a ggplot using one of the geom_*() functions.\n\n\nFor this plot, you want to use geom_point(). This geom simply adds point to the plot based on the data in the polite data frame.\nTo add geoms to a plot, you write a + at the end of the ggplot() command and include the geom on the next line. For example:\n\nggplot(\n  data = polite,\n  mapping = aes(x = f0mn, y = H1H2)\n) +\n  geom_point()\n\nWarning: Removed 12 rows containing missing values (`geom_point()`).\n\n\n\n\n\nThis type of plot, with two continuous axes and data represented by points, is called a scatter plot.\n\n\n\n\n\n\nScatter plot\n\n\n\nA scatter plot is a plot with two numeric axes and points indicating the data. It is used when you want to show the relationship between two numeric variables.\nTo create a scatter plot, use the geom_point() geometry.\n\n\nWhen writing your results section, you could describe the plot this way:\n\nFigure 1 shows a scatter plot of mean f0 on the x-axis and H1-H2 difference on the y-axis. The plot suggest an overall negative relationship between mean f0 and H1-H2 difference. In other words, increasing mean f0 corresponds to decreasing breathiness.\n\n\n\n\n\n\n\nWarning\n\n\n\nNote that using the + is a quirk of ggplot(). The idea behind it is that you start from a bare plot and you add (+) layers of data on top of it. This is because of the philosophy behind the package, called the Layered Grammar of Graphics.\n\n\n\n\n3.3 Function arguments\nNote that the data and mapping arguments don’t have to be named explicitly (with data = and mapping =) in the ggplot() function, since they are obligatory and they are specified in that order.\n\nggplot(\n  polite,\n  aes(x = f0mn, y = H1H2)\n) +\n  geom_point()\n\n\n\n\nIn fact, you can also leave out x = and y =.\n\nggplot(\n  polite,\n  aes(f0mn, H1H2)\n) +\n  geom_point()\n\nWarning: Removed 12 rows containing missing values (`geom_point()`).\n\n\n\n\n\nTry running ?ggplot in the Console to see the arguments of the function and the order they appear in.\n\n\n\n\n\n\nQuiz 3\n\n\n\nWhich of the following will produce the same plot as the one above? Reason through it first without running the code, then run all of these to check whether they look the way you expected.\n\n ggplot(polite, aes(H1H2, f0mn)) + geom_point() ggplot(polite, aes(y = H1H2, x = f0mn)) + geom_point() ggplot(polite, aes(y = f0mn, x = H1H2)) + geom_point()\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nWhen specifying arguments, the order matters when not using the argument names.\nSo this aes(a, b) is different from aes(b, a).\nBut this aes(y = b, x = a) is the same as aes(a, b).\n\n\n\n\n\n\n\n3.4 What the pipe?!\nThe code of the latest plot can also be written this way.\n\npolite |&gt;\n  ggplot(aes(f0mn, H1H2)) +\n    geom_point()\n\nWait, what is that thing, |&gt;?\nIt’s called a pipe. Think of a pipe as a teleporter.\nThe pipe |&gt; teleports the data polite into the following function as the first argument. So polite |&gt; ggplot() is equivalent to ggplot(polite).\nFor now it might not make much sense using the pipe, but you will learn next week how to chain many functions one after the other using the pipe, at which point its usefulness will be more obvious.\nAs a sneak-peak, you will be able to filter the data before plotting it, like so:\n\npolite |&gt;\n  # include only rows where f0mn &lt; 300\n  filter(f0mn &lt; 300) |&gt;\n  ggplot(aes(f0mn, H1H2)) +\n    geom_point()"
  },
  {
    "objectID": "tutorials/tutorial-w04.html#render-your-quarto-file",
    "href": "tutorials/tutorial-w04.html#render-your-quarto-file",
    "title": "QML tutorial - Week 4",
    "section": "4 Render your Quarto file!",
    "text": "4 Render your Quarto file!\nNow that you have done all of this hard work, why don’t you try and render the Quarto file you’ve been working on to an HTML file?\nGo ahead, click on the “Render” button and if everything works fine you should see a rendered HTML file in a second!\nNote that you will be asked to render your Quarto files for the assessments, so I recommend you try this out now."
  },
  {
    "objectID": "tutorials/tutorial-w04.html#summary",
    "href": "tutorials/tutorial-w04.html#summary",
    "title": "QML tutorial - Week 4",
    "section": "5 Summary",
    "text": "5 Summary\nThat’s all for this week!\n\n\n\n\n\n\nQuarto\n\nQuarto files can be used to create dynamic and reproducible reports.\nMark-up languages are text-formatting systems that specify text formatting and structure using symbols or keywords. Markdown is the mark-up language that is used in Quarto documents.\nThe main parts of a .qmd file are the YAML header, text and code chunks.\n\nPlotting\n\nggplot2 is a plotting package from the tidyverse.\n\nTo create a basic plot, you use the ggplot() function and specify data and mapping.\nThe aes() function allows you to specify aesthetics (like axes, colours, …) in the mapping argument.\nGeometries map data values onto shapes in the plot. All geometry functions are of the type geom_*().\n\nScatter plots are created with geom_point() and can be used with two numeric variables."
  },
  {
    "objectID": "tutorials/tutorial-w02.html",
    "href": "tutorials/tutorial-w02.html",
    "title": "QML tutorial - Week 2",
    "section": "",
    "text": "Last week you started your R journey with the R Console.\nWorking with the R Console can quickly become a bit inefficient: imagine having to run a lot of code, read a lot of different files, keeping track of a lot of variables and so on…\nThis is what Integrated Development Environment (IDE) software comes in: an IDE is just a graphical interface to programming languages that offer users with a lot of features to help them streamline their workflow. (But don’t get fooled! You still have to learn how to code.)\nR has a dedicated IDE called RStudio. This is what we will use from this week on. Note that RStudio even works with Python and many other languages!\n\n\nBeginners usually have trouble understanding the difference between R and RStudio.\nLet’s use a car analogy.\nWhat makes the car go is the engine and you can control the engine through the dashboard.\nYou can think of R as an engine and RStudio as the dashboard.\n\n\n\n\n\n\n\nR\n\n\n\n\nR is a programming language.\nWe use programming languages to interact with computers.\nYou run commands written in a console and the related task is executed.\n\n\n\n\n\n\n\n\n\nRStudio\n\n\n\n\nRStudio is an Integrated Development Environment or IDE.\nIt helps you using R more efficiently.\nIt has a graphical user interface or GUI.\n\n\n\nThe next section will give you a tour of RStudio."
  },
  {
    "objectID": "tutorials/tutorial-w02.html#rstudio",
    "href": "tutorials/tutorial-w02.html#rstudio",
    "title": "QML tutorial - Week 2",
    "section": "",
    "text": "Last week you started your R journey with the R Console.\nWorking with the R Console can quickly become a bit inefficient: imagine having to run a lot of code, read a lot of different files, keeping track of a lot of variables and so on…\nThis is what Integrated Development Environment (IDE) software comes in: an IDE is just a graphical interface to programming languages that offer users with a lot of features to help them streamline their workflow. (But don’t get fooled! You still have to learn how to code.)\nR has a dedicated IDE called RStudio. This is what we will use from this week on. Note that RStudio even works with Python and many other languages!\n\n\nBeginners usually have trouble understanding the difference between R and RStudio.\nLet’s use a car analogy.\nWhat makes the car go is the engine and you can control the engine through the dashboard.\nYou can think of R as an engine and RStudio as the dashboard.\n\n\n\n\n\n\n\nR\n\n\n\n\nR is a programming language.\nWe use programming languages to interact with computers.\nYou run commands written in a console and the related task is executed.\n\n\n\n\n\n\n\n\n\nRStudio\n\n\n\n\nRStudio is an Integrated Development Environment or IDE.\nIt helps you using R more efficiently.\nIt has a graphical user interface or GUI.\n\n\n\nThe next section will give you a tour of RStudio."
  },
  {
    "objectID": "tutorials/tutorial-w02.html#rstudio-2",
    "href": "tutorials/tutorial-w02.html#rstudio-2",
    "title": "QML tutorial - Week 2",
    "section": "2 RStudio",
    "text": "2 RStudio\nWhen you open RStudio, you can see the window is divided into 3 panels:\n\nBlue (left): the R Console. This is basically the same thing as the R Console you have been using last week.\nGreen (top-right): the Environment tab.\nPurple (bottom-right): the Files tab.\n\n\nThe Console is where R commands can be executed.\nThe Environment tab lists the objects created with R, while in the Files tab you can navigate folders on your computer to get to files and open them in the file Editor.\n\n2.1 RStudio and Quarto projects\nRStudio is an IDE (see above) which allows you to work efficiently with R, all in one place.\nNote that files and data live in folders on your computer, outside of RStudio: do not think of RStudio as an app where you can save files in.\nAll the files that you see in the Files tab are files on your computer and you can access them from the Finder or File Explorer as you would with any other file.\nIn principle, you can open RStudio and then navigate to any folder or file on your computer.\nHowever, there is a more efficient way of working with RStudio: RStudio Projects.\n\n\n\n\n\n\nRStudio Projects\n\n\n\nAn RStudio Project is a folder on your computer that has an .Rproj file.\n\n\nA special type of RStudio project are Quarto Projects. We will use these in this course.\n\n\n\n\n\n\nQuarto Projects\n\n\n\nA Quarto Project is an RStudio project which has a _quarto.yml file.\n\n\nYou will learn a bit more about the _quarto.yml file below.\nYou can create as many Quarto Projects as you wish, and I recommend to create one per project (your dissertation, a research project, a course, etc…). Also, I strongly recommend that you DO NOT save projects on One Drive. This is known to cause issues, so it is best to save projects on your Documents folder, for example.\nWe will create a Quarto Project for this course (meaning, you will create a folder for the course which will be the Quarto Project). You will have to use this project/folder throughout the semester.\nTo create a new Quarto Project, click on the button that looks like a transparent light blue box with a plus, in the top-left corner of RStudio. A window like the one below will pop up.\n\nClick on New Directory then Quarto Project.\n\nNow, this will create a new folder (aka directory) on your computer and will make that an RStudio Project (meaning, it will add a file with the .Rproj extension to the folder; the name of the file will be the name of the project/folder).\nGive a name to your new project, something like the name of the course and year (e.g. dal-2024).\nThen you need to specify where to create this new folder/Project. Click on Browse… and navigate to the folder you want to create the new folder/Project in. DO NOT use One Drive, as mentioned above.\nWhen done, click on Create Project. RStudio will automatically open your new project.\n\nThe project folder will contain the following files:\n\nA _quarto.yml file, that tells RStudio this is a Quarto Project.\nA .qmd file, named after the name of project. You will learn about .qmd files next week.\nAn .rproj file, named after the name of the project. This file is there just to inform RStudio that this folder is a project and you are not supposed to edit it.\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen working through these tutorials, always make sure you are in the course’s RStudio Quarto Project you created.\nYou know you are in an RStudio Project because you can see the name of the Project in the top-right corner of RStudio, next to the light blue cube icon.\nIf you see Project (none) in the top-right corner, that means your are not in an RStudio Project.\nTo make sure you are in the RStudio project, to open the project go to the project folder in File Explorer or Finder and double click on the .Rproj file.\n\n\nThere are several ways of opening an RStudio Project:\n\nYou can go to the RStudio Project folder in Finder or File Explorer and double click on the .Rproj file.\nYou can click on File &gt; Open Project in the RStudio menu.\nYou can click on the project name in the top-right corner of RStudio, which will bring up a list of projects. Click on the desired project to open it.\n\n\n\n2.2 A few important settings\nBefore moving on, there are a few important settings that you need to change. See figure below for how they should look.\n\n\nOpen the RStudio preferences (Tools &gt; Global options..., might be different on Windows).\nUn-tick Restore .RData into workspace at startup.\n\nThis mean that every time you start RStudio you are working with a clean Environment. Not restoring the workspace ensures that the code you write is fully reproducible.\n\nSelect Never in Save workspace to .RData on exit.\n\nSince we are not restoring the workspace at start-up, we don’t need to save it. Remember that as long as you save the code, you will not lose any of your work! You will learn how to save code below.\n\nClick OK to confirm the changes.\n\n\n\n\n\n\n\nQuiz 1\n\n\n\nTrue or false?\n\nRStudio executes the code. TRUEFALSE\nR is a programming language. TRUEFALSE\nAn IDE is necessary to run R. TRUEFALSE\nRStudio projects are folders with an .Rproj file. TRUEFALSE\nThe project name is shown in the top-right corner of RStudio. TRUEFALSE"
  },
  {
    "objectID": "tutorials/tutorial-w02.html#running-code-in-the-console",
    "href": "tutorials/tutorial-w02.html#running-code-in-the-console",
    "title": "QML tutorial - Week 2",
    "section": "3 Running code in the Console",
    "text": "3 Running code in the Console\nNow you can run R code in the Console from within RStudio.\nTry the following:\n\napples &lt;- 10\noranges &lt;- 6\ndurians &lt;- 2\n\nfruit_n &lt;- sum(apples, oranges, durians)\ncat(\"We have in total\", fruit_n, \"fruits.\")\n\nWe have in total 18 fruits.\n\n\nThe sentence We have in total 18 fruits. will be printed on the Console.\nMoreover, you will see that the variables we created (apples, oranges, durians, fruit_n) are listed in the Environment tab in the top-right panel of RStudio.\nThis is much better than having to use ls() to remember which variables you have created.\nNow create three more variables:\n\nThey should all be vectors of at least three elements.\nYou should create one numeric, one character and one logical vector.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo create vectors, you should use the c() function.\n\n\n\nNow check the Environment tab: your new variables will be there. The values of each variable should be prefixed with:\n\nThe vector type: num for numeric, chr for character and logi for logical.\nAnd the length of the vector in the form [1:N] where N is the number of element/values in the vector.\n\nThat’s neat! You can obtain the length of a vector (i.e. the number of element/values) with the length() function.\n\n\n\n\n\n\nLength of a vector\n\n\n\nThe length of a vector is the number of values contained in the vector.\nYou can obtain the vector length with length().\n\n\nFor example:\n\nwords &lt;- c(\"gold\", \"nice\", \"up\", \"of\")\nlength(words)\n\n[1] 4\n\n\nRemember you can always check the type of vector with the class() function."
  },
  {
    "objectID": "tutorials/tutorial-w02.html#r-scripts",
    "href": "tutorials/tutorial-w02.html#r-scripts",
    "title": "QML tutorial - Week 2",
    "section": "4 R scripts",
    "text": "4 R scripts\nSo far, you’ve been asked to write code in the Console and run it there.\nBut this is not very efficient. Every time, you need to write the code and execute it in the right order and it quickly becomes very difficult to keep track of everything when things start getting more involved.\nA solution is to use R scripts.\n\n\n\n\n\n\nR script\n\n\n\nAn R script is a file with the .R extension that contains R code.\n\n\nFor the rest of this tutorial, you will write all code in an R script.\n\n4.1 Create an R script\nFirst, create a folder called code in your project folder. You can do so from withint RStudio, in the Files tab or you can just create the folder in the File Explorer/Finder. This will be the folder where you will save all of your R scripts and other code files.\nNow, to create a new R script, look at the top-left corner of RStudio: the first button to the left looks like a white sheet with a green plus sign. This is the New file button. Click on that and you will see a few options to create a new file.\nClick on R Script. A new empty R script will be created and will open in the File Editor window of RStudio.\n\n\n\n\n\n\n\nWarning\n\n\n\nNote that creating an R script does not automatically saves it on your computer. To do so, either use the keyboard short-cut CMD+S/CTRL+S or click on the floppy disk icon in the menu below the file tab.\n\n\n\n\n\n\n\nSave the file inside the code/ folder with the following name: tutorial-w02.R.\n\n\n\n\n\n\nWarning\n\n\n\nRemember that all the files of your RStudio project don’t live inside RStudio but on your computer.\nSo you can always access them from the Finder or File Explorer! However, do not open a file by double clicking on it from the Finder/File Explorer.\nRather, open the RStudio project by double clicking on the .Rproj file and then open files from RStudio to ensure you are working within the RStudio project and the working directory is set correctly. (See the tutorial from Week 1).\n\n\nNow your script is ready to be filled with code. Copy the following lines of code and paste them at the top of your R script (this is the same code as above).\n\napples &lt;- 10\noranges &lt;- 6\ndurians &lt;- 2\n\nfruit_n &lt;- sum(apples, oranges, durians)\ncat(\"We have in total\", fruit_n, \"fruits.\")\n\nwords &lt;- c(\"gold\", \"nice\", \"up\", \"of\")\nlength(words)\n\n\n\n4.2 Run code\nNow, there are several ways to run code.\nOne is to click on the Run button. You can find this in the top-right corner of the script window.\n\nWhen you click Run, R runs the line of code that currently has the text cursor (|) and then moves the cursor to the next line (you can click Run again to run the line and so on.) You can also select multiple lines on the script and click Run, and all the selected lines will be run.\nAn alternative way is to place the text cursor on the line of code you want to run and then press CMD+ENTER/CTRL+ENTER. This will run the line of code and move the text cursor to the next line of code, as if you had clicked Run.\nYou can even select multiple lines of code (as you would select text) and press CMD+ENTER/CTRL+ENTER to run multiple lines of code!\nNow that you know how to use R scripts and run code in them, I will assume that you will keep writing new code from this tutorial in your script and run it from there!\nIn the next section, you will learn how to extend R capabilities with packages."
  },
  {
    "objectID": "tutorials/tutorial-w02.html#r-packages",
    "href": "tutorials/tutorial-w02.html#r-packages",
    "title": "QML tutorial - Week 2",
    "section": "5 R packages",
    "text": "5 R packages\nWhen you install R, a library of packages is also installed. Packages provide R with extra functionalities, usually by making extra functions available for use. You can think of packages as “plug-ins” that you install once and then you can “activate” them when you need them. The library installed with R contains a set of packages that are collectively known as the base R packages, but you can install more any time!\nNote that the R library is a folder on your computer. Packages are not installed inside RStudio. Remember that RStudio is just an interface.\nYou can check all of the currently installed packages in the bottom-right panel of RStudio, in the Packages tab. There you can also install new packages.\n\n\n\n\n\n\nR library and packages\n\n\n\n\nThe R library contains the base R packages and all the user-installed packages.\nR packages provide R with extra functionalities and are installed into the R library.\n\n\n\n\n\n\n\n\n\nExtra: Where is my R library?\n\n\n\nIf you want to find the path of the R library on your computer, type .libPaths() in the Console. The function returns (i.e. outputs) the path or paths where your R library is.\n\n\n\n5.0.1 Install packages\nYou can install extra packages in the R library in two ways:\n\nYou can use the install.packages() function. This function takes the name of the package you want to install as a string, for example install.packages(\"cowsay\")\nOr you can go the Packages tab in the bottom-right panel of RStudio and click on Install. A small window will pop up. See the screenshot below.\n\n\n\n\n\n\nGo ahead and try to install a package using the second method. Install the cowsay and the fortunes packages (see picture above for how to write the packages). After installing you will see that the package fortunes is listed in the Packages tab.\n\n\n\n\n\n\nInstall packages\n\n\n\nTo install packages, fo to the Packages tab of the bottom-right panel of RStudio and click on Install.\nIn the “Install packages” window, list the package names and then click Install.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nYou need to install a package ONLY ONCE! Once installed, it’s there for ever, saved in the R library. You will be able to use all of your installed packages in any RStudio project you create.\n\n\n\n\n5.0.2 Attach packages\nNow, to use a package you need to attach the package to the current R session with the library() function. Attaching a package makes the functions that come with the package available to us.\n\n\n\n\n\n\nWarning\n\n\n\nYou need to attach the packages you want to use once per R session.\nNote that every time you open RStudio, a new R session is started.\n\n\nLet’s attach the cowsay and fortunes packages. Write the following code at the top of your R script, before all the other code you wrote.\n\nlibrary(cowsay)\nlibrary(fortunes)\n\nNote that library(cowsay) takes the name of the package without quotes, although if you put the name in quotes it also works. You need one library() function per package (there are other ways, but we will stick with this one).\n\n\n\n\n\n\nAttaching packages\n\n\n\nPackages are attached with the library(pkg.name) function, where pkg.name is the name of the package.\nIt is customary to put all the packages used in the script at the top of the script.\n\n\nNow you can use the functions provided by the attached packages. Try out the say() function from the cowsay package.\nWrite the following in your R script and run it!\n\nsay(\"hot diggity\", \"frog\")\n\n(I know, the usefulness of the package might be questionable, but it is fun!)\n\n\n\n\n\n\nWarning\n\n\n\nRemember, you need to install a package only once but you need to attach it with library() every time you start R.\nThink of install.packages() as mounting a light bulb (installing the package) and library() as the light switch (attaching the package).\n\n\n\n\n\n5.1 Package documentation\nTo learn what a function does, you can check its documentation by typing in the Console the function name preceded by a ? question mark. Type ?say in the Console and hit ENTER to see the function documentation. You should see something like this:\n\n\n\n\n\nThe Description section is usually a brief explanation of what the function does.\nIn the Usage section, the usage of the function is shown by showing which arguments the function has and which default values (if any) each argument has. When the argument does not have a default value, NULL is listed as the value.\nThe Arguments section gives a thorough explanation of each function argument. (Ignore … for now).\nHow many arguments does say() have? How many arguments have a default value?\nDefault argument values allow you to use the function without specifying those arguments. Just write say() in your script on a new line and run it. Does the output make sense based on the Usage section of the documentation?\nThe rest of the function documentation usually has further details, which are followed by Examples. It is always a good idea to look at the example and test them in the Console when learning new functions.\n\n\n\n\n\n\nQuiz 2\n\n\n\nWhich of the following statements is wrong?\n\n You attach libraries with library(). install.packages() does not load packages. The R library is a folder."
  },
  {
    "objectID": "tutorials/tutorial-w02.html#including-comments",
    "href": "tutorials/tutorial-w02.html#including-comments",
    "title": "QML tutorial - Week 2",
    "section": "6 Including comments",
    "text": "6 Including comments\nSometimes we might want to add a few lines of text in our script, for example to take notes.\nYou can add so-called comments in R scripts, simply by starting a line with #. If you add # at the end of a line, anything after that will be considered a comment. Comments are simply skipped when R runs code.\n\n\n\n\n\n\nComments\n\n\n\nYou can add text comments in R scripts by starting a new line with # or by writing text preceded by # at the end of any line of code.\n\n\nFor example:\n\n# This is a comment. Let's add 6 + 3.\n6 + 3\n\n[1] 9\n\n3 + 6 # is the same as 6 + 3\n\n[1] 9\n\n# You can write long comments like this, for example if you want to explain what\n# the code does or if you want remind yourself of something. It is usual practice\n# to start new lines when comments are very long, each line preceded by #. We\n# call these \"comment blocks\"\n\n\n\n\n\n\n\nQuiz 4\n\n\n\nIs the following a valid and complete line of R code? TRUEFALSE\nsum(3, 2 #)  4"
  },
  {
    "objectID": "tutorials/tutorial-w02.html#summary",
    "href": "tutorials/tutorial-w02.html#summary",
    "title": "QML tutorial - Week 2",
    "section": "7 Summary",
    "text": "7 Summary\nYou made it! You completed this week’s tutorial.\nHere’s a summary of what you learnt.\n\n\n\n\n\n\n\nR is a programming language while RStudio is an IDE.\nQuarto projects are folders with an .Rproj file (you can see the name of the project you are currently in in the top-right corner of RStudio).\nR scripts contain R code and help you keep track of the code you run.\nR packages provide R with extra functionalities. The R library is a folder with all the installed packages.\n.libPaths() returns the path(s) to the R library.\nlibrary() attaches R packages (i.e. makes the package’s functions available for use).\nYou can inspect the documentation of any function by running ?function in the Console (where function is the function’s name, e.g. ?paste).\nYou can write text comments in R scripts by starting a line with #."
  },
  {
    "objectID": "slides/lecture-w06.html#summary-measures",
    "href": "slides/lecture-w06.html#summary-measures",
    "title": "Data Analysis for LEL - Week 6",
    "section": "Summary measures",
    "text": "Summary measures"
  },
  {
    "objectID": "slides/lecture-w06.html#summary-measures-1",
    "href": "slides/lecture-w06.html#summary-measures-1",
    "title": "Data Analysis for LEL - Week 6",
    "section": "Summary measures",
    "text": "Summary measures\n\nWe can summarise variables using summary measures.\n\n\n\nThere are two types of summary measures.\nMeasures of central tendency\n\nMeasures of central tendency indicate the typical or central value of a sample.\n\nMeasures of dispersion\n\nMeasures of dispersion indicate the spread or dispersion of the sample values around the central tendency value.\n\n\n\n\n.bg-washed-yellow.b–gold.ba.bw2.br3.shadow-5.ph4.mt2[ Always report a measure of central tendency together with its measure of dispersion! :::"
  },
  {
    "objectID": "slides/lecture-w06.html#measures-of-central-tendency",
    "href": "slides/lecture-w06.html#measures-of-central-tendency",
    "title": "Data Analysis for LEL - Week 6",
    "section": "Measures of central tendency",
    "text": "Measures of central tendency\n\nMean\n\\[\\bar{x} = \\frac{\\sum_{i=1}^{n} x_i}{n} = \\frac{x_1 + ... + x_n}{n}\\]\n\n\n\nMedian\n\\[\\text{if } n \\text{ is odd, } x_\\frac{n+1}{2}\\]\n\\[\\text{if } n \\text{ is even,  } \\frac{x_\\frac{n}{2} + x_\\frac{n}{2}}{2}\\]\n\n\n\n\nMode\nThe most common value."
  },
  {
    "objectID": "slides/lecture-w06.html#measures-of-dispersion",
    "href": "slides/lecture-w06.html#measures-of-dispersion",
    "title": "Data Analysis for LEL - Week 6",
    "section": "Measures of dispersion",
    "text": "Measures of dispersion\n\nMinimum and maximum values\n\n\n\nRange\n\\[ max(x) - min(x)\\]\nThe difference between the largest and smallest value.\n\n\n\n\nStandard deviation\n\\[\\text{SD} = \\sqrt{\\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{n-1}} = \\sqrt{\\frac{(x_1 - \\bar{x})^2 + ... + (x_n - \\bar{x})^2}{n-1}}\\]"
  },
  {
    "objectID": "slides/lecture-w06.html#mean",
    "href": "slides/lecture-w06.html#mean",
    "title": "Data Analysis for LEL - Week 6",
    "section": "Mean",
    "text": "Mean\nUse the mean with numeric continuous variables, if:\n\nThe variable can take on any positive and negative number, including 0.\n\n\n\n[1] -0.354\n\n\n\nThe variable can take on any positive number only.\n\n\n\n[1] 1.122\n\n\n\n\nDon’t take the mean of proportions and percentages!\nBetter to calculate the proportion/percentage across the entire data, rather than take the mean of individual proportions/percentages: see this blog post. If you really really have to, use the median."
  },
  {
    "objectID": "slides/lecture-w06.html#median",
    "href": "slides/lecture-w06.html#median",
    "title": "Data Analysis for LEL - Week 6",
    "section": "Median",
    "text": "Median\nUse the median with numeric (continuous and discrete) variables.\n\n\n[1] 0.09\n\n\n[1] -2.10 -1.12  0.09  0.41  0.95\n\n\n[1] 1.09\n\n\n[1] 0.12 0.32 1.09 1.50 2.58"
  },
  {
    "objectID": "slides/lecture-w06.html#median-1",
    "href": "slides/lecture-w06.html#median-1",
    "title": "Data Analysis for LEL - Week 6",
    "section": "Median",
    "text": "Median\n\n\n[1] 6.5\n\n\n[1]  3  4  6  7  9 15"
  },
  {
    "objectID": "slides/lecture-w06.html#median-2",
    "href": "slides/lecture-w06.html#median-2",
    "title": "Data Analysis for LEL - Week 6",
    "section": "Median",
    "text": "Median\n\n\n[1] 6.5\n\n\n[1] 7.333333\n\n\n[1] 6.5\n\n\n[1] 11.5"
  },
  {
    "objectID": "slides/lecture-w06.html#median-3",
    "href": "slides/lecture-w06.html#median-3",
    "title": "Data Analysis for LEL - Week 6",
    "section": "Median",
    "text": "Median\n\n\nThe mean is very sensitive to outliers.\nThe median is not."
  },
  {
    "objectID": "slides/lecture-w06.html#mode",
    "href": "slides/lecture-w06.html#mode",
    "title": "Data Analysis for LEL - Week 6",
    "section": "Mode",
    "text": "Mode\nUse the mode with categorical (discrete) variables.\n\n\n\n  blue  green    red yellow \n     2      1      3      2 \n\n\nThe mode is the most frequent value: red.\n\n\nLikert scales are ordinal (categorical) variables, so the mean and median are not appropriate!\nYou should use the mode (You can use the median with Likert scales if you really really need to…)"
  },
  {
    "objectID": "slides/lecture-w06.html#minimum-and-maximum",
    "href": "slides/lecture-w06.html#minimum-and-maximum",
    "title": "Data Analysis for LEL - Week 6",
    "section": "Minimum and maximum",
    "text": "Minimum and maximum\nReport minimum and maximum values for any numeric variable.\n\n\n[1] -2.1\n\n\n[1] 0.95\n\n\n[1] -2.10  0.95"
  },
  {
    "objectID": "slides/lecture-w06.html#range",
    "href": "slides/lecture-w06.html#range",
    "title": "Data Analysis for LEL - Week 6",
    "section": "Range",
    "text": "Range\nUse the range with any numeric variable.\n\n\n[1] 3.05\n\n\n[1] 2.46\n\n\n[1] 12"
  },
  {
    "objectID": "slides/lecture-w06.html#standard-deviation",
    "href": "slides/lecture-w06.html#standard-deviation",
    "title": "Data Analysis for LEL - Week 6",
    "section": "Standard deviation",
    "text": "Standard deviation\nUse the standard deviation with numeric continuous variables, if:\n\nThe variable can take on any positive and negative number, including 0.\n\n\n\n[1] 1.23658\n\n\n\nThe variable can take on any positive number only.\n\n\n\n[1] 0.9895555\n\n\n\n\nStandard deviations are relative and depend on the measurement unit/scale!\n\n–\n\nDon’t use the standard deviation with proportions and percentages!"
  },
  {
    "objectID": "slides/lecture-w06.html#summary-measures-overview",
    "href": "slides/lecture-w06.html#summary-measures-overview",
    "title": "Data Analysis for LEL - Week 6",
    "section": "Summary measures overview",
    "text": "Summary measures overview"
  },
  {
    "objectID": "slides/lecture-w06.html#summary",
    "href": "slides/lecture-w06.html#summary",
    "title": "Data Analysis for LEL - Week 6",
    "section": "Summary",
    "text": "Summary\n\n\nThe sample \\(y\\) is generated by a (random) variable \\(Y\\).\nA (statistical) variable is any characteristics, number, or quantity that can be measured or counted.\nVariables can be numeric or categorical.\n\nNumeric variables can be continuous or discrete.\nCategorical variables are only discrete.\n\nWe operationalise a measure/observation as a numeric or a categorical variable.\nWe summarise variables using summary measures:\n\nMeasures of central tendency indicate the typical or central value of a sample.\nMeasures of dispersion indicate the spread or dispersion of the sample values around the central tendency value."
  },
  {
    "objectID": "slides/lecture-w04.html#good-data-visualisation",
    "href": "slides/lecture-w04.html#good-data-visualisation",
    "title": "Data Analysis for LEL - Week 4",
    "section": "Good data visualisation",
    "text": "Good data visualisation\n\nAlberto Cairo has identified four common features of good data visualisation (Spiegelhalter 2019:64–66):\n\nIt contains reliable information.\nThe design has been chosen so that relevant patterns become noticeable.\nIt is presented in an attractive manner, but appearance should not get in the way of honesty, clarity and depth.\nWhen appropriate, it is organized in a way that enables some exploration."
  },
  {
    "objectID": "slides/lecture-w04.html#endangerment-status",
    "href": "slides/lecture-w04.html#endangerment-status",
    "title": "Data Analysis for LEL - Week 4",
    "section": "Endangerment status",
    "text": "Endangerment status\n\nglot_status\n\n# A tibble: 8,345 × 18\n   ID        Language_ID Parameter_ID Value Code_ID Comment Source codeReference\n   &lt;chr&gt;     &lt;chr&gt;       &lt;chr&gt;        &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  &lt;lgl&gt;        \n 1 kolp1236… kolp1236    aes          3     aes-sh… Kol (1… hh:he… NA           \n 2 tana1288… tana1288    aes          3     aes-sh… Tanahm… hh:he… NA           \n 3 touo1238… touo1238    aes          3     aes-sh… Touo (… hh:he… NA           \n 4 bert1248… bert1248    aes          3     aes-sh… Fadash… hh:he… NA           \n 5 sius1254… sius1254    aes          6     aes-ex… Siusla… hh:he… NA           \n 6 cent2045… cent2045    aes          6     aes-ex… Jalaa … &lt;NA&gt;   NA           \n 7 else1239… else1239    aes          3     aes-sh… Elseng… hh:he… NA           \n 8 taia1239… taia1239    aes          4     aes-mo… Taiap … hh:he… NA           \n 9 pyuu1245… pyuu1245    aes          3     aes-sh… Pyu (4… hh:he… NA           \n10 mato1253… mato1253    aes          6     aes-ex… Arára … hh:he… NA           \n# ℹ 8,335 more rows\n# ℹ 10 more variables: status &lt;fct&gt;, Name &lt;chr&gt;, Macroarea &lt;chr&gt;,\n#   Latitude &lt;dbl&gt;, Longitude &lt;dbl&gt;, Glottocode &lt;chr&gt;, ISO639P3code &lt;chr&gt;,\n#   Countries &lt;chr&gt;, Family_ID &lt;chr&gt;, Language_ID.y &lt;chr&gt;"
  },
  {
    "objectID": "slides/lecture-w04.html#information-is-not-reliable",
    "href": "slides/lecture-w04.html#information-is-not-reliable",
    "title": "Data Analysis for LEL - Week 4",
    "section": "Information is (not) reliable",
    "text": "Information is (not) reliable"
  },
  {
    "objectID": "slides/lecture-w04.html#information-is-reliable",
    "href": "slides/lecture-w04.html#information-is-reliable",
    "title": "Data Analysis for LEL - Week 4",
    "section": "Information is reliable",
    "text": "Information is reliable"
  },
  {
    "objectID": "slides/lecture-w04.html#patterns-are-not-noticeable",
    "href": "slides/lecture-w04.html#patterns-are-not-noticeable",
    "title": "Data Analysis for LEL - Week 4",
    "section": "Patterns are (not) noticeable",
    "text": "Patterns are (not) noticeable"
  },
  {
    "objectID": "slides/lecture-w04.html#patterns-are-noticeable",
    "href": "slides/lecture-w04.html#patterns-are-noticeable",
    "title": "Data Analysis for LEL - Week 4",
    "section": "Patterns are noticeable",
    "text": "Patterns are noticeable"
  },
  {
    "objectID": "slides/lecture-w04.html#aesthetics-should-not-get-in-the-way",
    "href": "slides/lecture-w04.html#aesthetics-should-not-get-in-the-way",
    "title": "Data Analysis for LEL - Week 4",
    "section": "Aesthetics (should not) get in the way",
    "text": "Aesthetics (should not) get in the way\n\nImage source. See more examples on Ugly Charts."
  },
  {
    "objectID": "slides/lecture-w04.html#enables-exploration",
    "href": "slides/lecture-w04.html#enables-exploration",
    "title": "Data Analysis for LEL - Week 4",
    "section": "Enables exploration",
    "text": "Enables exploration"
  },
  {
    "objectID": "slides/lecture-w04.html#practical-tips",
    "href": "slides/lecture-w04.html#practical-tips",
    "title": "Data Analysis for LEL - Week 4",
    "section": "Practical tips",
    "text": "Practical tips\n\n\nShow raw data (e.g. individual observations, participants, items…).\nSeparate data in different panels as needed.\nUse simple but informative labels for axes, panels, etc…\nUse colour as a visual aid, not just for aesthetics.\nReuse labels, colours, shapes throughout different plots to indicate the same thing."
  },
  {
    "objectID": "slides/lecture-w02.html#research-process",
    "href": "slides/lecture-w02.html#research-process",
    "title": "Data Analysis for LEL - Week 2",
    "section": "Research process",
    "text": "Research process"
  },
  {
    "objectID": "slides/lecture-w02.html#research-rationale",
    "href": "slides/lecture-w02.html#research-rationale",
    "title": "Data Analysis for LEL - Week 2",
    "section": "Research rationale",
    "text": "Research rationale"
  },
  {
    "objectID": "slides/lecture-w02.html#research-cycle",
    "href": "slides/lecture-w02.html#research-cycle",
    "title": "Data Analysis for LEL - Week 2",
    "section": "Research cycle",
    "text": "Research cycle"
  },
  {
    "objectID": "slides/lecture-w02.html#research-cycle-the-dangers",
    "href": "slides/lecture-w02.html#research-cycle-the-dangers",
    "title": "Data Analysis for LEL - Week 2",
    "section": "Research cycle: the dangers",
    "text": "Research cycle: the dangers"
  },
  {
    "objectID": "slides/lecture-w02.html#replication-in-linguistics",
    "href": "slides/lecture-w02.html#replication-in-linguistics",
    "title": "Data Analysis for LEL - Week 2",
    "section": "Replication in linguistics",
    "text": "Replication in linguistics\n\n[O]nly 1 in 1,250 experimental linguistic articles contains an independent direct replication.\n\n\nThe observed smaller number of citations of replication studies compared to corresponding initial studies is also in line with the lack of perceived value of replication studies reported in other fields.\n\n—Korback and Roettger 2023"
  },
  {
    "objectID": "slides/lecture-w02.html#statistical-power-in-linguistics",
    "href": "slides/lecture-w02.html#statistical-power-in-linguistics",
    "title": "Data Analysis for LEL - Week 2",
    "section": "Statistical power in linguistics",
    "text": "Statistical power in linguistics\n\nAn opportunistic review of seven papers from the November 2017 issue of this journal containing statistical analyses of acoustic speech production data found the number of participants to range from 11 to 39.\n\n—Kirby and Sonderegger 2018\n\nIn group differences research, the median sample sizes (n = 18 and n = 14 for case and control groups, respectively) were insufficient for detecting large, medium, or small effect sizes.\n\n—Gaeta and Brydges 2020\n\n[O]f the 1004 studies reviewed by Lehtonen et al. (2018) 878 had sample sizes smaller than 50 participants per group (i.e., 87%) and 987 had sample sizes smaller than 100 (98%).\n\n—Brysbaert 2020"
  },
  {
    "objectID": "slides/lecture-w02.html#case-study-participant-number-in-prosody-research",
    "href": "slides/lecture-w02.html#case-study-participant-number-in-prosody-research",
    "title": "Data Analysis for LEL - Week 2",
    "section": "Case study: participant number in prosody research",
    "text": "Case study: participant number in prosody research\nThe dataset contains data from 113 studies, published between 1955 and 2017 (the bulk of studies is within the range 1990-2017 though). The median number of speakers per study is 5. (An estimate of number of speakers per study in phonetics, Coretta 2019)."
  },
  {
    "objectID": "slides/lecture-w02.html#case-study-participant-number-in-prosody-research-1",
    "href": "slides/lecture-w02.html#case-study-participant-number-in-prosody-research-1",
    "title": "Data Analysis for LEL - Week 2",
    "section": "Case study: participant number in prosody research",
    "text": "Case study: participant number in prosody research"
  },
  {
    "objectID": "slides/lecture-w02.html#reproducibility-in-linguistics",
    "href": "slides/lecture-w02.html#reproducibility-in-linguistics",
    "title": "Data Analysis for LEL - Week 2",
    "section": "Reproducibility in linguistics",
    "text": "Reproducibility in linguistics\n\n35% of the articles were published open access and the rates of sharing materials, data, and protocols were below 10%. None of the articles reported preregistrations, 1% reported replications, and 10% had conflict of interest statements. These rates have not increased noticeably between 2008/2009 and 2018/2019.\n\n—Bochynska et al. 2023"
  },
  {
    "objectID": "slides/lecture-w02.html#activity",
    "href": "slides/lecture-w02.html#activity",
    "title": "Data Analysis for LEL - Week 2",
    "section": "Activity",
    "text": "Activity\n\nSearch for a paper you are interested in or that you have recently read.\nFill in the following spreadsheet with info on the paper you picked.\n\nSpreadsheet."
  },
  {
    "objectID": "slides/lecture-w02.html#open-scholarship-practices",
    "href": "slides/lecture-w02.html#open-scholarship-practices",
    "title": "Data Analysis for LEL - Week 2",
    "section": "Open Scholarship practices",
    "text": "Open Scholarship practices\n\n\nPre-registration and Registered Reports.\nShare the Research Compendium (data, materials, code, etc).\nEnsure your study is reproducible.\nThink about sample size.\n\n\n\n\n\nBe open, go Open!"
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Set-up instructions",
    "section": "",
    "text": "Important\n\n\n\nThe PPLS Computer Lab will have all the necessary software, but if you wish to use your own laptop you can follow these instructions."
  },
  {
    "objectID": "setup.html#r-and-rstudio",
    "href": "setup.html#r-and-rstudio",
    "title": "Set-up instructions",
    "section": "1 R and RStudio",
    "text": "1 R and RStudio\nYou must install both R and RStudio (they are two separate pieces of software).\n\nMake sure your operating system is up-to-date.\nThe latest version of R (https://cloud.r-project.org).\nThe latest version of RStudio (https://www.rstudio.com/products/rstudio/download/#download)."
  },
  {
    "objectID": "setup.html#quarto",
    "href": "setup.html#quarto",
    "title": "Set-up instructions",
    "section": "2 Quarto",
    "text": "2 Quarto\nFollow the installation instructions for Quarto on the Get Started page."
  },
  {
    "objectID": "data/winter2020/polite.html",
    "href": "data/winter2020/polite.html",
    "title": "Taste and smell words form an affectively loaded and emotionally flexible part of the English lexicon",
    "section": "",
    "text": "subject\n\nSubject unique identifier (categorical).\n\ngender\n\nGender of subject (categorical).\n\nbirthplace\n\nBirth place of subject (categorical).\n\nmusicstudent\n\nDoes the subject have music training? (binary: yes, no)\n\nscenario\n\nUnique identifier of different items.\n\ntask\n\nTask type (categorical: not = mailbox task vs dct = discourse completion task). In the mailbox task people left a note on somebody’s mailbox, while in the discourse completion task they were prompted to role-play the start of a conversation.\n\nattitude\n\nAttitude (binary: pol polite vs inf informal).\n\ntotal_duration\n\nTotal duration of utterances in seconds (numeric).\n\narticulation_rate\n\nNumber of syllables per second (numeric).\n\nf0mn\n\nMean fundamental frequency (f0) (numeric).\n\nf0sd\n\nStadard deviation of fundamental frequency (numeric).\n\nf0range\n\nMinimum and maximum fundamental frequency (numeric).\n\ninmn\n\nMean intensity (numeric).\n\ninsd\n\nStandard deviation of intensity (numeric).\n\ninrange\n\nMinimum and maximum fundamental frequency (numeric).\n\nshimmer\n\nLocal shimmer (likewise normalized amplitude difference of consecutive periods) (numeric).\n\njitter\n\nLocal jitter (bsolute period-to-period difference divided by the average period) (numeric).\n\nHNRmn\n\nMean Harmonics-to-Noise Ratio (numeric).\n\nH1H2\n\nDifference between first and second harmonic (H1-H2) (numeric).\n\nbreath_count\n\nNumber of audible breath intakes (count).\n\nfiller_count\n\nNumber of oral fillers like “oh/ah” (count).\n\nhiss_count\n\nNumber of noisy breath intakes (count).\n\nnasal_count\n\nNumber of nasal fillers like “mh/nh” (count).\n\nsil_count\n\nNumber of silent pauses (count).\n\nya_count\n\nNumber of occurences of interjection “ya” (informal) (count).\n\nyey_count\n\nNumber of occurences of interjection “yey” (polite) (count)."
  },
  {
    "objectID": "data/winter2020/polite.html#description",
    "href": "data/winter2020/polite.html#description",
    "title": "Taste and smell words form an affectively loaded and emotionally flexible part of the English lexicon",
    "section": "",
    "text": "subject\n\nSubject unique identifier (categorical).\n\ngender\n\nGender of subject (categorical).\n\nbirthplace\n\nBirth place of subject (categorical).\n\nmusicstudent\n\nDoes the subject have music training? (binary: yes, no)\n\nscenario\n\nUnique identifier of different items.\n\ntask\n\nTask type (categorical: not = mailbox task vs dct = discourse completion task). In the mailbox task people left a note on somebody’s mailbox, while in the discourse completion task they were prompted to role-play the start of a conversation.\n\nattitude\n\nAttitude (binary: pol polite vs inf informal).\n\ntotal_duration\n\nTotal duration of utterances in seconds (numeric).\n\narticulation_rate\n\nNumber of syllables per second (numeric).\n\nf0mn\n\nMean fundamental frequency (f0) (numeric).\n\nf0sd\n\nStadard deviation of fundamental frequency (numeric).\n\nf0range\n\nMinimum and maximum fundamental frequency (numeric).\n\ninmn\n\nMean intensity (numeric).\n\ninsd\n\nStandard deviation of intensity (numeric).\n\ninrange\n\nMinimum and maximum fundamental frequency (numeric).\n\nshimmer\n\nLocal shimmer (likewise normalized amplitude difference of consecutive periods) (numeric).\n\njitter\n\nLocal jitter (bsolute period-to-period difference divided by the average period) (numeric).\n\nHNRmn\n\nMean Harmonics-to-Noise Ratio (numeric).\n\nH1H2\n\nDifference between first and second harmonic (H1-H2) (numeric).\n\nbreath_count\n\nNumber of audible breath intakes (count).\n\nfiller_count\n\nNumber of oral fillers like “oh/ah” (count).\n\nhiss_count\n\nNumber of noisy breath intakes (count).\n\nnasal_count\n\nNumber of nasal fillers like “mh/nh” (count).\n\nsil_count\n\nNumber of silent pauses (count).\n\nya_count\n\nNumber of occurences of interjection “ya” (informal) (count).\n\nyey_count\n\nNumber of occurences of interjection “yey” (polite) (count)."
  },
  {
    "objectID": "data/tucker2019/mald_1_1.html",
    "href": "data/tucker2019/mald_1_1.html",
    "title": "Massive Auditory Lexical Decision 1.1",
    "section": "",
    "text": "Subject\n\nSubject unique identifier.\n\nItem\n\nWord.\n\nIsWord\n\nWhether it is a real word or a nonce word.\n\nPhonLev\n\nMean phoneme-level Levenshtein distance.\n\nRT\n\nReaction times (ms).\n\nACC\n\nAccuracy of lexical decision.\n\nRT_log\n\nLogged reaction times."
  },
  {
    "objectID": "data/tucker2019/mald_1_1.html#description",
    "href": "data/tucker2019/mald_1_1.html#description",
    "title": "Massive Auditory Lexical Decision 1.1",
    "section": "",
    "text": "Subject\n\nSubject unique identifier.\n\nItem\n\nWord.\n\nIsWord\n\nWhether it is a real word or a nonce word.\n\nPhonLev\n\nMean phoneme-level Levenshtein distance.\n\nRT\n\nReaction times (ms).\n\nACC\n\nAccuracy of lexical decision.\n\nRT_log\n\nLogged reaction times."
  },
  {
    "objectID": "data/ota2009/key-rock.html",
    "href": "data/ota2009/key-rock.html",
    "title": "The KEY to the ROCK: Near-homophony in nonnative visual word recognition",
    "section": "",
    "text": "The data contains only trials from the Japanese participants.\n\nSubject\n\nParticipant ID.\n\nProcedure\n\nWhether the trial is a practice (PracticeProc) of a test trial (TrialProc).\n\nVersion\n\nTrial version.\n\nContrast\n\nType of contrast (F filler, H homophone, LR /l~r/, P phonological, PB /p~b/).\n\nItem\n\nItem number.\n\nCondition\n\nTrial condition (whether the pair contains Control, Related, or Unrelated words),\n\nWordL\n\nWord shown on the left-side of the screen.\n\nWordR\n\nWord shown on the right-side of the screen.\n\nWords.ACC\n\nWhether the participant correctly identified the pair being related or unrelated.\n\nWords.RT\n\nReaction time of response in milliseconds."
  },
  {
    "objectID": "data/ota2009/key-rock.html#description",
    "href": "data/ota2009/key-rock.html#description",
    "title": "The KEY to the ROCK: Near-homophony in nonnative visual word recognition",
    "section": "",
    "text": "The data contains only trials from the Japanese participants.\n\nSubject\n\nParticipant ID.\n\nProcedure\n\nWhether the trial is a practice (PracticeProc) of a test trial (TrialProc).\n\nVersion\n\nTrial version.\n\nContrast\n\nType of contrast (F filler, H homophone, LR /l~r/, P phonological, PB /p~b/).\n\nItem\n\nItem number.\n\nCondition\n\nTrial condition (whether the pair contains Control, Related, or Unrelated words),\n\nWordL\n\nWord shown on the left-side of the screen.\n\nWordR\n\nWord shown on the right-side of the screen.\n\nWords.ACC\n\nWhether the participant correctly identified the pair being related or unrelated.\n\nWords.RT\n\nReaction time of response in milliseconds."
  },
  {
    "objectID": "data/koppensteiner2016/takete_maluma.html",
    "href": "data/koppensteiner2016/takete_maluma.html",
    "title": "Shaking Takete and Flowing Maluma. Non-Sense Words Are Associated with Motion Patterns",
    "section": "",
    "text": "Tak_Mal_Stim\n\nThe nature of the stimulus (Takete vs Maluma),\n\nAnswer\n\nAccuracy of response (CORRECT vs INCORRECT). Whether the participant has correctly identified the stimulus nature.\n\nCorr_1_Wrong_0\n\nSame as Answer but coded with 0 and 1.\n\nRater\n\nID of the participant.\n\nFemale_0\n\nParticipant’s gender (female = 0, male = 1)."
  },
  {
    "objectID": "data/koppensteiner2016/takete_maluma.html#description",
    "href": "data/koppensteiner2016/takete_maluma.html#description",
    "title": "Shaking Takete and Flowing Maluma. Non-Sense Words Are Associated with Motion Patterns",
    "section": "",
    "text": "Tak_Mal_Stim\n\nThe nature of the stimulus (Takete vs Maluma),\n\nAnswer\n\nAccuracy of response (CORRECT vs INCORRECT). Whether the participant has correctly identified the stimulus nature.\n\nCorr_1_Wrong_0\n\nSame as Answer but coded with 0 and 1.\n\nRater\n\nID of the participant.\n\nFemale_0\n\nParticipant’s gender (female = 0, male = 1)."
  },
  {
    "objectID": "data/coretta2018/formants.html",
    "href": "data/coretta2018/formants.html",
    "title": "Formant trajectories in Italian and Polish",
    "section": "",
    "text": "speaker\n\nspeaker’s ID\n\nfile\n\naudio chunk file name\n\nword\n\nword stimulus\n\ntime\n\ntime point within vowel (9 points per vowel)\n\nf1\n\nF1 (Hz)\n\nf2\n\nF2 (Hz)\n\nf3\n\nF3 (Hz)\n\nf4\n\nfundamental frequency (F0) (Hz)\n\nlanguage\n\nspeaker’s native language (Italian, Polish)\n\ngender\n\nspeaker’s gender (f, m)\n\nglottocode\n\nlanguage Glottocode\n\nitem\n\nword ID number\n\nipa\n\nIPA transcription of the word\n\nc1\n\nfirst consonant (C1)\n\nc1_phonation\n\nvoicing of C1 (voiceless, voiced)\n\nvowel\n\nV1 and V2 (a, o, u)\n\nanteropost\n\nbackness of the vowel (back, central)\n\nheight\n\nheight of the vowel (high, mid, low)\n\nc2\n\nsecond consonant (C2)\n\nc2_phonation\n\nvoicing of C2 (voiceless or voiced)\n\nc2_place\n\nplace of C2 (coronal, `velar``)"
  },
  {
    "objectID": "data/coretta2018/formants.html#description",
    "href": "data/coretta2018/formants.html#description",
    "title": "Formant trajectories in Italian and Polish",
    "section": "",
    "text": "speaker\n\nspeaker’s ID\n\nfile\n\naudio chunk file name\n\nword\n\nword stimulus\n\ntime\n\ntime point within vowel (9 points per vowel)\n\nf1\n\nF1 (Hz)\n\nf2\n\nF2 (Hz)\n\nf3\n\nF3 (Hz)\n\nf4\n\nfundamental frequency (F0) (Hz)\n\nlanguage\n\nspeaker’s native language (Italian, Polish)\n\ngender\n\nspeaker’s gender (f, m)\n\nglottocode\n\nlanguage Glottocode\n\nitem\n\nword ID number\n\nipa\n\nIPA transcription of the word\n\nc1\n\nfirst consonant (C1)\n\nc1_phonation\n\nvoicing of C1 (voiceless, voiced)\n\nvowel\n\nV1 and V2 (a, o, u)\n\nanteropost\n\nbackness of the vowel (back, central)\n\nheight\n\nheight of the vowel (high, mid, low)\n\nc2\n\nsecond consonant (C2)\n\nc2_phonation\n\nvoicing of C2 (voiceless or voiced)\n\nc2_place\n\nplace of C2 (coronal, `velar``)"
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nyear\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n2022\n\n\n‘Everywhere here can say this’: The English locative impersonal\n\n\nSluckin, Benjamin L., Itamar Kastner\n\n\n\n\n2020\n\n\nA Cross-Cultural Analysis of Early Prelinguistic Gesture Development and Its Relationship to Language Development\n\n\nThea Cameron-Faulkner, Nivedita Malik, Circle Steele, Stefano Coretta, Ludovica Serratrice, Elena Lieven\n\n\n\n\n2018\n\n\nAcoustics and articulatory durational measures of Italian and Polish\n\n\nStefano Coretta\n\n\n\n\n2021\n\n\nAlbanian Voice Onset Time\n\n\nStefano Coretta\n\n\n\n\n2018\n\n\nFormant trajectories in Italian and Polish\n\n\nStefano Coretta\n\n\n\n\n2022\n\n\nGlottolog 4.6 data: Agglomerated Endangerment Status\n\n\nStefano Coretta, Harald Hammarström, Robert Forkel, Martin Haspelmath, Sebastian Bank\n\n\n\n\n2021\n\n\nMassive Auditory Lexical Decision 1.1\n\n\nTucker, Benjamin V.\n\n\n\n\n2020\n\n\nSecond language users exhibit shallow morphological processing\n\n\nSong, Y., Do, Y., Thompson, A., Waegemaekers, E., Lee, J.\n\n\n\n\n2016\n\n\nShaking Takete and Flowing Maluma. Non-Sense Words Are Associated with Motion Patterns\n\n\nMarkus Koppensteiner, Pia Stephan, Johannes Paul, Michael Jäschke\n\n\n\n\n2016\n\n\nTaste and smell words form an affectively loaded and emotionally flexible part of the English lexicon\n\n\nBodo Winter\n\n\n\n\n2009\n\n\nThe KEY to the ROCK: Near-homophony in nonnative visual word recognition\n\n\nMitsuhiko Ota, Robert J. Hartsuiker, Sara L. Haywood\n\n\n\n\n2012\n\n\nThe phonetic profile of Korean formal and informal speech registers\n\n\nBodo Winter, Sven Grawunder\n\n\n\n\n2021\n\n\nThe role of relevance for scalar diversity\n\n\nElizabeth Pankratz, Bob van Tiel\n\n\n\n\n2023\n\n\nV2-Relatives in Old English\n\n\nBettelou Los, Stefano Coretta\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "assessments.html",
    "href": "assessments.html",
    "title": "DAL",
    "section": "",
    "text": "This course will be assessed on the basis of 2 formative assessments and 2 summative assessments.\nFormative assessments are mock assessments that give you the chance for an interim check in with what you have learnt and what you might need to revise. They will not be individually marked, but a model answer will be shared after the deadline. There will be two formative assessments.\nYou will have to submit two summative assessments, each covering all the course content. They will weight 50% and 50% of the final mark.\nSee below for details (DETAILS TO BE ADDED)."
  },
  {
    "objectID": "assessments.html#assessment-overview",
    "href": "assessments.html#assessment-overview",
    "title": "DAL",
    "section": "",
    "text": "This course will be assessed on the basis of 2 formative assessments and 2 summative assessments.\nFormative assessments are mock assessments that give you the chance for an interim check in with what you have learnt and what you might need to revise. They will not be individually marked, but a model answer will be shared after the deadline. There will be two formative assessments.\nYou will have to submit two summative assessments, each covering all the course content. They will weight 50% and 50% of the final mark.\nSee below for details (DETAILS TO BE ADDED)."
  },
  {
    "objectID": "assessments.html#feedback-and-marking",
    "href": "assessments.html#feedback-and-marking",
    "title": "DAL",
    "section": "2 Feedback and marking",
    "text": "2 Feedback and marking\nThe formative assessments will not be individually marked and feedback will consist of a model answer, shared after the formative deadline. You will receive individual feedback for the summative assessments, as comments on the submitted file in Turnitin.\nThe comments will be categorised according the the Feedback Categorisation Rubric used for this course, which you can see here. The rubric is based on the learning outcomes of the course. For each criterion in the rubric there are three possible outcomes: insufficient, developing, proficient. This should help you identify areas of strength and those that can be improved.\nNote that the Feedback Categorisation Form is not used to calculate a numeric mark. Marking will follow the PPLS MSc Common Marking Scheme, which you can find here (login required).\nMore specifically, we will use a “step marking” procedure, where, within each mark band, you can get a 2, 5 or 8 (for example, 62, 65 or 68). We will not use other numbers within the scale. These are the criteria for getting 2, 5, or 8:\n\n2: The criteria for the mark band have been achieved, but there might be minor issues.\n5: The criteria for the mark band have been achieved fully.\n8: The criteria for the mark band have been achieved fully and in a particularly remarkable way, but not in such a way to grant a higher mark band.\n\nFinally, please note that marking does not follow a point-based system, i.e. different exercises are not assigned a specific amount of points you can obtain and we will instead adopt an “impression-based” marking system, based on the descriptors of the PPLS MSC Common Marking Scheme."
  },
  {
    "objectID": "assessments.html#formative-assessments",
    "href": "assessments.html#formative-assessments",
    "title": "DAL",
    "section": "3 Formative assessments",
    "text": "3 Formative assessments\n\n\n\n\n\n\nFormative 1: Week 5 (Thu 19 October at noon)\n\n\n\nReading and visualising data\nThis formative assessments covers Weeks 1-4.\n\n\n\n\n\n\n\n\n\nFormative 2: Week 10 (Thu 7 March at noon)\n\n\n\nData transformation\nThis formative assessments covers Weeks 1-6."
  },
  {
    "objectID": "assessments.html#summative-assessments",
    "href": "assessments.html#summative-assessments",
    "title": "DAL",
    "section": "4 Summative assessments",
    "text": "4 Summative assessments\n\n\n\n\n\n\nSummative 1: Week 10 (Thu 28 March at noon)\n\n\n\nDue on Thursday 28 March at noon\nThe first summative contains 2 guided exercises that cover things done in Weeks 1 to 7.\n\n\n\n\n\n\n\n\n\nSummative 2: Thu 25 Apr at noon\n\n\n\nDue on Thursday 25 April at noon\nFor the second summative assessment you will have to find a data set from published research of your choice and write a short data analysis report on the chosen data.\nYou must submit to Turnitin for approval a brief description of the data set including a link to the relevant publication, by Monday 25th March.\nThe summative assessment report is due on 25 April and should include:\n\nA brief explanation of the study the data comes from (remember to include proper attribution by citing relevant publications).\nA general description of the data frame (number and types of columns, number of observations, summary measures).\nPlots that illustrate patterns in the data (at least 5). Each plot should be accompanied by a caption and a textual description."
  },
  {
    "objectID": "content.html",
    "href": "content.html",
    "title": "DAL",
    "section": "",
    "text": "Week\nLecture\nLab\n\n\n\n\n\n1\nQuantitative methods and uncertainty\nR basics\n\n\n\n2\nResearch process\nRStudio + R scripts\n\n\n\n3\nFile management\nRead data\n\n\n\n4\nData viz\nQuarto + Plotting basics\n\n\n\n5\nStatistical variables\nData transformation I\nF1\n\n\nFL\nNo classes\n\n\n\n\n6\nData summaries\nData transformation II\n\n\n\n7\nTidy data\nData tidying\nF2\n\n\n8\nPlot design\nAdvanced plotting\n\n\n\n9\nTroubleshooting\nFixing errors\n\n\n\n25 Mar\n\n\nS2 proposal\n\n\n28 Mar\n\n\nS1\n\n\n25 Apr\n\n\nS2"
  },
  {
    "objectID": "content.html#schedule-overview",
    "href": "content.html#schedule-overview",
    "title": "DAL",
    "section": "",
    "text": "Week\nLecture\nLab\n\n\n\n\n\n1\nQuantitative methods and uncertainty\nR basics\n\n\n\n2\nResearch process\nRStudio + R scripts\n\n\n\n3\nFile management\nRead data\n\n\n\n4\nData viz\nQuarto + Plotting basics\n\n\n\n5\nStatistical variables\nData transformation I\nF1\n\n\nFL\nNo classes\n\n\n\n\n6\nData summaries\nData transformation II\n\n\n\n7\nTidy data\nData tidying\nF2\n\n\n8\nPlot design\nAdvanced plotting\n\n\n\n9\nTroubleshooting\nFixing errors\n\n\n\n25 Mar\n\n\nS2 proposal\n\n\n28 Mar\n\n\nS1\n\n\n25 Apr\n\n\nS2"
  },
  {
    "objectID": "content.html#weekly-schedule",
    "href": "content.html#weekly-schedule",
    "title": "DAL",
    "section": "2 Weekly schedule",
    "text": "2 Weekly schedule\n\n2.1 Week 1\n\n\n\n\n\n\nLearning Objectives\n\n\n\n\n\nQuestions\n\nWhat is quantitative data analysis?\nIs statistics a science, an art, or both?\nHow do uncertainty and variability affect data analysis?\n\nSkills\n\nThink critically about statistics, uncertainty and variability.\nUse R to perform simple calculations.\nMaster the basics of the programming language R.\n\n\n\n\n\n\n\n\n\n\nHomework\n\n\n\n\n\nCourse website\n\nCarefully read the homepage.\nFamiliarise yourself with this Course content page (note that the materials will be updated throughout the course).\n\nIntake form\n\nYou must complete the intake form before coming to the Tuesday lecture.\nThe link to the form can be found on the Learn website.\n\nOPTIONAL: Install R, RStudio and Quarto\n\nThe labs will take place in the PPLS computer lab which will have all the necessary software (hopefully…).\nIf instead you wish to use your own laptop, you are welcome to do so provided you take care of installing everything and fix issues that might arise. We won’t be able to help you with the installation process.\nPlease, follow the instructions in the Setup page.\n\n\n\n\n\n\n\n\n\n\nReadings\n\n\n\n\n\nALL READINGS ARE OPTIONAL. The textbook can be used to revise what done in class and you can pick and choose any of the other readings based on your interests.\nTextbook\nThis course will be loosely based on the following online textbook. Note that the order of the contents of the course will not closely follow that of this book, but specific chapter will be noted on this page in each week\n\nR for Data Science (R4DS).\n\nOther\n\nEllis and Levy 2008. Framework of Problem-Based Research: A Guide for Novice Researchers on the Development of a Research-Worthy Problem.\nMethods as theory.\nVasishth and Gelman 2021. How to embrace variation and accept uncertainty in linguistic and psycholinguistic data analysis.\nMolnar 2022. Modeling Mindsets: The many cultures of learning from data.\nDarwin Holmes 2020. Researcher Positionality - A Consideration of Its Influence and Place in Qualitative Research - A New Researcher Guide\nJafar 2018. What is positionality and should it be expressed in quantitative studies?"
  },
  {
    "objectID": "data/coretta2018/token-measures.html",
    "href": "data/coretta2018/token-measures.html",
    "title": "Acoustics and articulatory durational measures of Italian and Polish",
    "section": "",
    "text": "index\n\nobservation number within speaker\n\nspeaker\n\nspeaker’s ID\n\nfile\n\naudio chunk file name\n\nrec_date\n\ndate and time of recording\n\nipu\n\nSPPAS IPU index\n\nprompt\n\nsentence stimulys\n\nword\n\nword stimulus\n\ntime\n\ntime of the sentence onset within the concatenated audio file (s)\n\nsentence_ons\n\nonset time of the sentence (s)\n\nsentence_off\n\noffset time of the sentence (s)\n\nword_ons\n\nonset time of the target word (s)\n\nword_off\n\noffset time of the target word (= C1 onset) (s)\n\nv1_ons\n\nonset time of V1 (= C1 offset) (s)\n\nc2_ons\n\nonset time of C2 (= V1 offset) (s)\n\nv2_ons\n\nonset time of V2 (= C2 offset) (s)\n\nc1_rel\n\ntime of C1 release (s)\n\nc2_rel\n\ntime of C2 release (s)\n\nvoicing_start\n\ntime of voicing onset (s)\n\nvoicing_end\n\ntime of voicing offset (s)\n\nvoicing_duration\n\nduration of voiced interval (ms)\n\nvoiced_points\n\nnumber of points out of 5 within the first half of C1 closure in which voicing is present\n\nGONS\n\nonset of C1 closing gesture (s)\n\nmax\n\ntime of maximum displacement of C1 closing gesture (s)\n\nNOFF\n\noffset of C1 gesture nucleus (s)\n\nNONS\n\nonset of C1 gesture nucleus (s)\n\npeak1\n\nfirst tongue velocity peak (s)\n\npeak2\n\nsecond tongue velocity peak (s)\n\nc1_duration\n\nduration of C1 (ms)\n\nc1_clos_duration\n\nduration of C1 closure (ms)\n\nc1_vot\n\nC1 Voice Onset Time (ms)\n\nc1_rvofft\n\nC1 release to V1 offset time (ms)\n\nv1_duration\n\nduration of V1 (ms)\n\nc1_duration\n\nduration of C1 (ms)\n\nc2_clos_duration\n\nduration of C2 closure (ms)\n\nv2_duration\n\nduration of V2 (ms)\n\nv_v\n\nV1 onset to V2 onset (Vowel-to-Vowel) duration (ms)\n\nword_duration\n\nduration of the word (ms)\n\nsentence_duration\n\nduration of sentence (s)\n\nlanguage\n\nspeaker’s native language (Italian, Polish)\n\ngender\n\nspeaker’s sex (f, m)\n\nglottocode\n\nlanguage Glottocode\n\nitem\n\nword ID number\n\nipa\n\nIPA transcription of the word\n\nc1\n\nfirst consonant (C1)\n\nc1_phonation\n\nvoicing of C1 (voiceless, voiced)\n\nvowel\n\nV1 and V2 (a, o, u)\n\nanteropost\n\nbackness of the vowel (back, central)\n\nheight\n\nheight of the vowel (high, mid, low)\n\nc2\n\nsecond consonant (C2)\n\nc2_phonation\n\nvoicing of C2 (voiceless or voiced)\n\nc2_place\n\nplace of C2 (coronal, velar)\n\nspeech_rate\n\nspeech rate as syllables per second\n\nspeech_rate_c\n\ncentred speech rate as syllables per second"
  },
  {
    "objectID": "data/coretta2018/token-measures.html#description",
    "href": "data/coretta2018/token-measures.html#description",
    "title": "Acoustics and articulatory durational measures of Italian and Polish",
    "section": "",
    "text": "index\n\nobservation number within speaker\n\nspeaker\n\nspeaker’s ID\n\nfile\n\naudio chunk file name\n\nrec_date\n\ndate and time of recording\n\nipu\n\nSPPAS IPU index\n\nprompt\n\nsentence stimulys\n\nword\n\nword stimulus\n\ntime\n\ntime of the sentence onset within the concatenated audio file (s)\n\nsentence_ons\n\nonset time of the sentence (s)\n\nsentence_off\n\noffset time of the sentence (s)\n\nword_ons\n\nonset time of the target word (s)\n\nword_off\n\noffset time of the target word (= C1 onset) (s)\n\nv1_ons\n\nonset time of V1 (= C1 offset) (s)\n\nc2_ons\n\nonset time of C2 (= V1 offset) (s)\n\nv2_ons\n\nonset time of V2 (= C2 offset) (s)\n\nc1_rel\n\ntime of C1 release (s)\n\nc2_rel\n\ntime of C2 release (s)\n\nvoicing_start\n\ntime of voicing onset (s)\n\nvoicing_end\n\ntime of voicing offset (s)\n\nvoicing_duration\n\nduration of voiced interval (ms)\n\nvoiced_points\n\nnumber of points out of 5 within the first half of C1 closure in which voicing is present\n\nGONS\n\nonset of C1 closing gesture (s)\n\nmax\n\ntime of maximum displacement of C1 closing gesture (s)\n\nNOFF\n\noffset of C1 gesture nucleus (s)\n\nNONS\n\nonset of C1 gesture nucleus (s)\n\npeak1\n\nfirst tongue velocity peak (s)\n\npeak2\n\nsecond tongue velocity peak (s)\n\nc1_duration\n\nduration of C1 (ms)\n\nc1_clos_duration\n\nduration of C1 closure (ms)\n\nc1_vot\n\nC1 Voice Onset Time (ms)\n\nc1_rvofft\n\nC1 release to V1 offset time (ms)\n\nv1_duration\n\nduration of V1 (ms)\n\nc1_duration\n\nduration of C1 (ms)\n\nc2_clos_duration\n\nduration of C2 closure (ms)\n\nv2_duration\n\nduration of V2 (ms)\n\nv_v\n\nV1 onset to V2 onset (Vowel-to-Vowel) duration (ms)\n\nword_duration\n\nduration of the word (ms)\n\nsentence_duration\n\nduration of sentence (s)\n\nlanguage\n\nspeaker’s native language (Italian, Polish)\n\ngender\n\nspeaker’s sex (f, m)\n\nglottocode\n\nlanguage Glottocode\n\nitem\n\nword ID number\n\nipa\n\nIPA transcription of the word\n\nc1\n\nfirst consonant (C1)\n\nc1_phonation\n\nvoicing of C1 (voiceless, voiced)\n\nvowel\n\nV1 and V2 (a, o, u)\n\nanteropost\n\nbackness of the vowel (back, central)\n\nheight\n\nheight of the vowel (high, mid, low)\n\nc2\n\nsecond consonant (C2)\n\nc2_phonation\n\nvoicing of C2 (voiceless or voiced)\n\nc2_place\n\nplace of C2 (coronal, velar)\n\nspeech_rate\n\nspeech rate as syllables per second\n\nspeech_rate_c\n\ncentred speech rate as syllables per second"
  },
  {
    "objectID": "data/coretta2022/glot_status.html",
    "href": "data/coretta2022/glot_status.html",
    "title": "Glottolog 4.6 data: Agglomerated Endangerment Status",
    "section": "",
    "text": "ID\n\nPrimary key.\n\nLanguage_ID\n\nReference to languages$ID.\n\nParameter_ID\n\nParameter ID.\n\nValue\n\nParameter value.\n\nCode_ID\n\nCode ID.\n\nComment\n\nComment.\n\nSource\n\nSource reference.\n\ncodeReference\n\n\n\nstatus\n\nAgglomerate Endangerment Status.\n\nName\n\nName of the language.\n\nMacroarea\n\nGeographic macro-area.\n\nLatitude\n\nLatitude.\n\nLongitude\n\nLongitude.\n\nGlottocode\n\nGlottocode.\n\nISO639P3code\n\nISO639-3 code.\n\nCountries\n\nCountries where the language is spoken.\n\nFamily_ID\n\nFamily ID.\n\nLanguage_ID.y\n\nLanguage ID."
  },
  {
    "objectID": "data/coretta2022/glot_status.html#description",
    "href": "data/coretta2022/glot_status.html#description",
    "title": "Glottolog 4.6 data: Agglomerated Endangerment Status",
    "section": "",
    "text": "ID\n\nPrimary key.\n\nLanguage_ID\n\nReference to languages$ID.\n\nParameter_ID\n\nParameter ID.\n\nValue\n\nParameter value.\n\nCode_ID\n\nCode ID.\n\nComment\n\nComment.\n\nSource\n\nSource reference.\n\ncodeReference\n\n\n\nstatus\n\nAgglomerate Endangerment Status.\n\nName\n\nName of the language.\n\nMacroarea\n\nGeographic macro-area.\n\nLatitude\n\nLatitude.\n\nLongitude\n\nLongitude.\n\nGlottocode\n\nGlottocode.\n\nISO639P3code\n\nISO639-3 code.\n\nCountries\n\nCountries where the language is spoken.\n\nFamily_ID\n\nFamily ID.\n\nLanguage_ID.y\n\nLanguage ID."
  },
  {
    "objectID": "data/song2020/shallow.html",
    "href": "data/song2020/shallow.html",
    "title": "Second language users exhibit shallow morphological processing",
    "section": "",
    "text": "Group\n\nParticipant group (L1, L2).\n\nID\n\nSubject unique identifier.\n\nList\n\nWord list.\n\nTarget\n\nTarget word.\n\nRT\n\nReaction time (ms).\n\nRT_log\n\nLogged reaction time.\n\nCritical_Filler\n\nWhether the trial is a critical or a filler trial.\n\nWord_Nonword\n\nWhether the word is a real word or a nonce word (only word is present in the data).\n\nRelation_type\n\nWhether the relation type is Unrelated, Constituent, or NonConstituent.\n\nBranching\n\nWhether the trial word is Left-branching or Right-branching."
  },
  {
    "objectID": "data/song2020/shallow.html#description",
    "href": "data/song2020/shallow.html#description",
    "title": "Second language users exhibit shallow morphological processing",
    "section": "",
    "text": "Group\n\nParticipant group (L1, L2).\n\nID\n\nSubject unique identifier.\n\nList\n\nWord list.\n\nTarget\n\nTarget word.\n\nRT\n\nReaction time (ms).\n\nRT_log\n\nLogged reaction time.\n\nCritical_Filler\n\nWhether the trial is a critical or a filler trial.\n\nWord_Nonword\n\nWhether the word is a real word or a nonce word (only word is present in the data).\n\nRelation_type\n\nWhether the relation type is Unrelated, Constituent, or NonConstituent.\n\nBranching\n\nWhether the trial word is Left-branching or Right-branching."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Analysis for LEL",
    "section": "",
    "text": "Welcome to the main site of the course Data Analysis for Linguistics and English Language (Semester 2).\nThis website is your go-to place throughout the semester for any info related to the course.\n\n\n\n\n\n\nCourse description\n\n\n\nThis course is an introduction to quantitative data analysis (including data wrangling, visualisation and modelling) as commonly employed in linguistics, using the R software.\nWe will cover the following topics:\n\nThe basics of quantitative data analysis.\nData preparation.\nData summaries.\nPrinciples of data visualisation.\n\nAt completion of the course you will have gained the following skills:\n\nImport common data formats, tidy and transform data.\nChoosing and reporting appropriate summary measures.\nUsing compelling visualisations to communicate a specific message about patterns in the data.\n\nExamples from different branches of linguistics will be used to provide you with hands-on experience in quantitative data analysis and Open Research practices.\n\n\n\n\n\n\n\n\nCourse rationale\n\n\n\nThis course is designed to help you develop the necessary skills for conducting and interpreting analyses of data as commonly employed in linguistics.\nThe content and objectives of the course are in response to recent advances in our understanding of the theory behind research methods.\nRecent meta-scientific research has identified three important aspects of research: the reproducibility, replicability and generalisability.\n\nA result is reproducible when the same analysis steps performed on the same dataset consistently produces the same answer.\nA result is replicable when the same analysis performed on different datasets produces qualitatively similar answers.\nA result is generalisable when a different analysis workflow performed on different data sets produces qualitatively similar answers.\n\nSee Definitions for a more detailed explanation.\nHowever, based on surveys from different disciplines, we are currently facing the three research crises (reproducibility, replicability and generalisability crises) by which most results are neither reproducible, nor replicable, nor generalisable (Munafò et al. 2017, Simmons et al. 2011, Ioannidis 2005, Yarkoni 2022).\nThe Open Research movement (also known as Open Science or Open Scholarship, Crüwell et al. 2019) was developed with the aim of improving our understanding of these crises and with the objective of providing researchers with guidelines and tools to produce reproducible, replicable and generalisable research.\nThe statistical philosophy adopted in the course is that of the New Statistics (Cumming 2014, Kruschke and Liddell 2018. The main goal of the New Statistics is to shift the attention from statistical significance to estimation with quantification of uncertainty.\n\n\n\n\n\n\n\n\nAsk for help\n\n\n\nIf at any point during the course you don’t feel comfortable with any aspect of the course, you are unsure about anything that has been covered in class or in your own time, you are struggling to keep up with the course workload, you are experiencing mental of physical distress due to a pre-existing or new illness, medical condition or disability, or you find yourself unable to access basic needs like food or housing, please do get in touch with me and/or the PPLS support (go to the PPLS UG or MSc Hub on SharePoint &gt; Support for students &gt; Health & Wellbeing).\nWe are humans first and the rapidly-changing new world we are living in now can put us under pressure. What is most important to me is that you are first and foremost healthy and able to participate to the course, and that you succeed and get the most out of the course.\nIt is OK not to be OK, and remember that you are not alone. Other people, teachers and students, might be struggling right now or have struggled before and might have gone through what you are going through now. Remember that support exists for you, so please do reach out. If you see somebody close to you struggling, please let them know about the available support network and encourage them to reach out.\n\n\n\n\n\n\n\n\nContacts\n\n\n\nYou can reach me (Stefano) at s.coretta@ed.ac.uk or on Teams.\nIf you want to book office hours with me or the tutors, you can do so here: https://bit.ly/33BH84L. Location depends on whom you are seeing and which day, so check the confirmation email for that info!"
  },
  {
    "objectID": "slides/lecture-w01.html#course-info",
    "href": "slides/lecture-w01.html#course-info",
    "title": "Data Analysis for LEL - Week 1",
    "section": "Course info",
    "text": "Course info\n\n\nThe main course website https://uoelel.github.io/dal/.\nCourse announcements are sent via Learn.\nASK FOR HELP: It is OK not to be OK, and remember that you are not alone.\n\nGo to the PPLS UG or PG Hub (on SharePoint Online) &gt; Support for students &gt; Wellbeing and Health.\nCome to my office hours (booking link on the course website homepage).\n\nAssessment:\n\nFormative assessments: Two formative assessments.\nSummative assessments: Two summative assessments (50-50).\nInfo on the course website."
  },
  {
    "objectID": "slides/lecture-w01.html#course-rationale",
    "href": "slides/lecture-w01.html#course-rationale",
    "title": "Data Analysis for LEL - Week 1",
    "section": "Course rationale",
    "text": "Course rationale\n\n\nDAL (Data Analysis for LEL) is a new course designed for undergraduate students.\nThe main learning objective of this course is to allow you to conduct basic data reports which can be applied to linguistic questions and data, for example as part of your dissertation.\nWe will focus on modern techniques of data handling and quantitative analysis.\n\n\n\n\n\nThis is not a programming course. (For that, see the Advanced R book).\nThere will be little maths.\nThe course covers the basics, but you will very likely have to learn something extra for your dissertation.\nWe will not cover inferential statistics (including significance testing)."
  },
  {
    "objectID": "slides/lecture-w01.html#research-methods",
    "href": "slides/lecture-w01.html#research-methods",
    "title": "Data Analysis for LEL - Week 1",
    "section": "Research methods",
    "text": "Research methods"
  },
  {
    "objectID": "slides/lecture-w01.html#research-process",
    "href": "slides/lecture-w01.html#research-process",
    "title": "Data Analysis for LEL - Week 1",
    "section": "Research process",
    "text": "Research process"
  },
  {
    "objectID": "slides/lecture-w01.html#research-process-1",
    "href": "slides/lecture-w01.html#research-process-1",
    "title": "Data Analysis for LEL - Week 1",
    "section": "Research process",
    "text": "Research process"
  },
  {
    "objectID": "slides/lecture-w01.html#data-analysis",
    "href": "slides/lecture-w01.html#data-analysis",
    "title": "Data Analysis for LEL - Week 1",
    "section": "Data analysis",
    "text": "Data analysis"
  },
  {
    "objectID": "slides/lecture-w01.html#what-is-the-purpose-of-data-analysis",
    "href": "slides/lecture-w01.html#what-is-the-purpose-of-data-analysis",
    "title": "Data Analysis for LEL - Week 1",
    "section": "What is the purpose of data analysis?",
    "text": "What is the purpose of data analysis?\n\nDiscuss in small groups.\nWrite your group answers on Wooclap."
  },
  {
    "objectID": "slides/lecture-w01.html#data-analysis-1",
    "href": "slides/lecture-w01.html#data-analysis-1",
    "title": "Data Analysis for LEL - Week 1",
    "section": "Data analysis",
    "text": "Data analysis"
  },
  {
    "objectID": "slides/lecture-w01.html#data-analysis-2",
    "href": "slides/lecture-w01.html#data-analysis-2",
    "title": "Data Analysis for LEL - Week 1",
    "section": "Data analysis",
    "text": "Data analysis\n\nThe numbers have no way of speaking for themselves. We speak for them. We imbue them with meaning.\n\n—Nate Silver, The Signal and the Noise"
  },
  {
    "objectID": "slides/lecture-w01.html#uncertainty-and-variability",
    "href": "slides/lecture-w01.html#uncertainty-and-variability",
    "title": "Data Analysis for LEL - Week 1",
    "section": "Uncertainty and variability",
    "text": "Uncertainty and variability"
  },
  {
    "objectID": "slides/lecture-w01.html#can-you-guess-what-this-is",
    "href": "slides/lecture-w01.html#can-you-guess-what-this-is",
    "title": "Data Analysis for LEL - Week 1",
    "section": "Can you guess what this is?",
    "text": "Can you guess what this is?"
  },
  {
    "objectID": "slides/lecture-w01.html#statistics-as-a-tool-to-deal-with-uncertainty-and-variability",
    "href": "slides/lecture-w01.html#statistics-as-a-tool-to-deal-with-uncertainty-and-variability",
    "title": "Data Analysis for LEL - Week 1",
    "section": "Statistics as a tool to deal with uncertainty and variability",
    "text": "Statistics as a tool to deal with uncertainty and variability\n\nStatistics is the science concerned with developing and studying methods for collecting, analyzing, interpreting and presenting empirical data. (From UCI Department of Statistics)\n\n\n\nStatistics is the technology of extracting information, illumination and understanding from data, often in the face of uncertainty. (From the British Academy)\n\n\n\n\nStatistics is a mathematical and conceptual discipline that focuses on the relation between data and hypotheses. (From the Standford Encyclopedia of Philosophy)\n\n\n\n\nStatistics as the art of applying the science of scientific methods. (From ORI Results, Nature)"
  },
  {
    "objectID": "slides/lecture-w01.html#statistics-as-an-art-and-as-a-science",
    "href": "slides/lecture-w01.html#statistics-as-an-art-and-as-a-science",
    "title": "Data Analysis for LEL - Week 1",
    "section": "Statistics as an art and as a science",
    "text": "Statistics as an art and as a science\n\nStatistic is both a science and an art\nIt is a science in that its methods are basically systematic and have general application and an art in that their successful application depends, to a considerable degree, on the skill and special experience of the statistician, and on his knowledge of the field of application.\n—L. H. C. Tippett"
  },
  {
    "objectID": "slides/lecture-w01.html#statistics-is-not-infallible",
    "href": "slides/lecture-w01.html#statistics-is-not-infallible",
    "title": "Data Analysis for LEL - Week 1",
    "section": "Statistics is not infallible",
    "text": "Statistics is not infallible\n\n\nBut…\nall that glisters is not gold"
  },
  {
    "objectID": "slides/lecture-w03.html#research-project-management",
    "href": "slides/lecture-w03.html#research-project-management",
    "title": "Data Analysis for LEL - Week 3",
    "section": "Research project management",
    "text": "Research project management"
  },
  {
    "objectID": "slides/lecture-w03.html#data-management-plan-dmp",
    "href": "slides/lecture-w03.html#data-management-plan-dmp",
    "title": "Data Analysis for LEL - Week 3",
    "section": "Data Management Plan (DMP)",
    "text": "Data Management Plan (DMP)\n\nA Data Management Plan (DMP) covers data types and volume, capture, storage, integrity, confidentiality, retention and destruction, sharing and deposit.\n\nUoE Research Data Management policy.\nUoE DMP online."
  },
  {
    "objectID": "slides/lecture-w03.html#research-compendium",
    "href": "slides/lecture-w03.html#research-compendium",
    "title": "Data Analysis for LEL - Week 3",
    "section": "Research Compendium",
    "text": "Research Compendium\n\nA research compendium accompanies, enhances, or is a scientific publication providing data, code, and documentation for reproducing a scientific workflow.\n\n—Research Compendium\n\n\nA research compendium is a collection of all digital parts of a research project including data, code, texts (protocols, reports, questionnaires, meta data). The collection is created in such a way that reproducing all results is straightforward.\n\n—The Turing Way: Research Compendia"
  },
  {
    "objectID": "slides/lecture-w03.html#organise-files",
    "href": "slides/lecture-w03.html#organise-files",
    "title": "Data Analysis for LEL - Week 3",
    "section": "Organise files",
    "text": "Organise files\n\n\nCreate one folder and make that the folder for your dissertation project.\nIn that folder, create folders for data/ and for scripts/ (and plots/, dissertation/, etc).\n\n\n\n\n\nIn data/ have a raw/ and derived/ folder:\n\nRaw data (data that, if lost, it is very unfortunate; for example, experiment data, data which was manually annotated, etc) should be saved in data/raw/.\nDerived data (data that is derived with scripts) should be saved in data/derived/."
  },
  {
    "objectID": "slides/lecture-w03.html#organise-files-example",
    "href": "slides/lecture-w03.html#organise-files-example",
    "title": "Data Analysis for LEL - Week 3",
    "section": "Organise files: example",
    "text": "Organise files: example"
  },
  {
    "objectID": "slides/lecture-w03.html#back-up",
    "href": "slides/lecture-w03.html#back-up",
    "title": "Data Analysis for LEL - Week 3",
    "section": "Back up",
    "text": "Back up\n\nMake sure you have a backup system in place.\n\n\n\n\nSave copies of the entire folder in an external hard drive.\nSaving copies of the entire folder in an online storage service (iCloud Drive, One Drive, DropBox, Google Drive, …).\n\nBut if you are working on that copy via syncing, make sure you have a second independent place you back up to, like a hard drive.\n\nUsing a versioning system like git."
  },
  {
    "objectID": "slides/lecture-w03.html#research-projects-are-dynamic",
    "href": "slides/lecture-w03.html#research-projects-are-dynamic",
    "title": "Data Analysis for LEL - Week 3",
    "section": "Research projects are dynamic",
    "text": "Research projects are dynamic\n\n\nBe prepared to change how files and folders are organised after you start.\nProjects evolve over time and sometimes you need to clean things up.\n\n\n\n\n\nUse a good system to mark versions in your files. Two simple systems:\n\nUse full DATE in the file name\n\ndissertation-2022-11-21.\ndissertation-2023-03-01.\n\nOr use version number\n\nInspired by Semantic versioning from programming but can be helpful with research files too!\ndissertation-v1.0.\ndissertation-v1.1.\ndissertation-v2.0."
  },
  {
    "objectID": "slides/lecture-w03.html#file-naming-donts",
    "href": "slides/lecture-w03.html#file-naming-donts",
    "title": "Data Analysis for LEL - Week 3",
    "section": "File naming don’ts",
    "text": "File naming don’ts"
  },
  {
    "objectID": "slides/lecture-w03.html#licensing",
    "href": "slides/lecture-w03.html#licensing",
    "title": "Data Analysis for LEL - Week 3",
    "section": "Licensing",
    "text": "Licensing\n\nA license gives someone official permission to reuse something while protecting the intellectual property of the original creator.\n\n\nUse open licenses to ensure the data/code can be used by other researchers.\nThe Creative Commons licenses are now common in research."
  },
  {
    "objectID": "slides/lecture-w03.html#activity",
    "href": "slides/lecture-w03.html#activity",
    "title": "Data Analysis for LEL - Week 3",
    "section": "Activity",
    "text": "Activity\n\nReorganise one of your project folders (for example your dissertation folder).\nOR read online materials on “research project management” (use your favourite search engine to search “research project management”)"
  },
  {
    "objectID": "slides/lecture-w05.html#sample-y",
    "href": "slides/lecture-w05.html#sample-y",
    "title": "Data Analysis for LEL - Week 5",
    "section": "Sample \\(y\\)",
    "text": "Sample \\(y\\)\n\nWhen we ask a research question, we collect a sample \\(y\\) from a population."
  },
  {
    "objectID": "slides/lecture-w05.html#sample-y-1",
    "href": "slides/lecture-w05.html#sample-y-1",
    "title": "Data Analysis for LEL - Week 5",
    "section": "Sample \\(y\\)",
    "text": "Sample \\(y\\)\n\n\\(y\\) is a sample of values (\\(y_1, y_2, y_3, ..., y_n\\)).\n\n\n\nSample of values can be e.g.:\n\nNumber of telic and atelic verbs in a historical corpus of Sanskrit.\nVoice Onset Time of stops from 50 speakers Mapudungun.\nFriendliness ratings of synthetic speech as indicated by 300 participants.\n…"
  },
  {
    "objectID": "slides/lecture-w05.html#sample-y-2",
    "href": "slides/lecture-w05.html#sample-y-2",
    "title": "Data Analysis for LEL - Week 5",
    "section": "Sample \\(y\\)",
    "text": "Sample \\(y\\)\n\n\\(y\\) is a sample of values (\\(y_1, y_2, y_3, ..., y_n\\)).\n\n\nWe say that the values in the sample \\(y\\) were generated by a (random) variable \\(Y\\)."
  },
  {
    "objectID": "slides/lecture-w05.html#variable-y",
    "href": "slides/lecture-w05.html#variable-y",
    "title": "Data Analysis for LEL - Week 5",
    "section": "Variable \\(Y\\)",
    "text": "Variable \\(Y\\)\n\n\\(Y\\) is a (random) variable that generates the values in the sample \\(y\\).\n\n\n\nA (statistical) variable is any characteristics, number, or quantity that can be measured or counted\n\nWhen you observe or measure something, you are taking note of the values generated by the variable.\nIt’s called variable because it varies (ha!).\nThe opposite of a variable is a constant."
  },
  {
    "objectID": "slides/lecture-w05.html#sample-y-3",
    "href": "slides/lecture-w05.html#sample-y-3",
    "title": "Data Analysis for LEL - Week 5",
    "section": "Sample \\(y\\)",
    "text": "Sample \\(y\\)\n\n\\(Y\\) is a (random) variable that generates the values in the sample \\(y\\).\n\n\nVariables can be e.g.:\n\nToken number of telic verbs and atelic verbs in written Sanskrit.\nVoice Onset Time of stops in Mapudungun.\nFriendliness ratings of synthetic speech.\n…"
  },
  {
    "objectID": "slides/lecture-w05.html#types-of-variables",
    "href": "slides/lecture-w05.html#types-of-variables",
    "title": "Data Analysis for LEL - Week 5",
    "section": "Types of variables",
    "text": "Types of variables"
  },
  {
    "objectID": "slides/lecture-w05.html#types-of-variables-1",
    "href": "slides/lecture-w05.html#types-of-variables-1",
    "title": "Data Analysis for LEL - Week 5",
    "section": "Types of variables",
    "text": "Types of variables"
  },
  {
    "objectID": "slides/lecture-w05.html#types-of-variables-2",
    "href": "slides/lecture-w05.html#types-of-variables-2",
    "title": "Data Analysis for LEL - Week 5",
    "section": "Types of variables",
    "text": "Types of variables\n\nNumeric continuous variable: between any two values there is an infinite number of values.\n\nThe variable can take on any positive and negative number, including 0.\nThe variable can take on any positive number only.\nProportions and percentages: The variable can take on any number between 0 and 1.\n\n\n\n\nNumeric discrete variable: between any two consecutive values there are no other values.\n\nCounts: The variable can take only on any positive integer number.\n\n\n\n\n\nCategorical (discrete) variable.\n\nBinary or dichotomous: The variable can take only one of two values.\nThe variable can take any of three of more values.\nOrdinal: The variable can take any of three of more values and the values have a natural order."
  },
  {
    "objectID": "slides/lecture-w05.html#operationalisation",
    "href": "slides/lecture-w05.html#operationalisation",
    "title": "Data Analysis for LEL - Week 5",
    "section": "Operationalisation",
    "text": "Operationalisation\n\nWe can operationalise something as a numeric or a categorical variable.\n\n\n\nThink of ways to operationalise the following:\n\nVoice Onset Time.\nFriendliness of speech.\nLexical frequency.\n…"
  },
  {
    "objectID": "slides/lecture-w05.html#operationalisation-1",
    "href": "slides/lecture-w05.html#operationalisation-1",
    "title": "Data Analysis for LEL - Week 5",
    "section": "Operationalisation",
    "text": "Operationalisation"
  },
  {
    "objectID": "slides/lecture-w05.html#summary",
    "href": "slides/lecture-w05.html#summary",
    "title": "Data Analysis for LEL - Week 5",
    "section": "Summary",
    "text": "Summary\n\n\nThe sample \\(y\\) is generated by a (random) variable \\(Y\\).\nA (statistical) variable is any characteristics, number, or quantity that can be measured or counted.\nVariables can be numeric or categorical.\n\nNumeric variables can be continuous or discrete.\nCategorical variables are only discrete.\n\nWe operationalise a measure/observation as a numeric or a categorical variable."
  },
  {
    "objectID": "tutorials/tutorial-w01.html",
    "href": "tutorials/tutorial-w01.html",
    "title": "QML tutorial - Week 1",
    "section": "",
    "text": "R can be used to analyse all sorts of data, from tabular data (also known as “spreadsheets”), textual data, geographic data and even images.\n\nThis course will focus on the analysis of tabular data, since all of the techniques relevant to this type of data also apply to the other types.\n\nThe R community is a very inclusive community and it’s easy to find help. There are several groups that promote R in minority/minoritised groups, like R-Ladies, Africa R, and Rainbow R just to mention a few.\nMoreover, R is open source and free!"
  },
  {
    "objectID": "tutorials/tutorial-w01.html#why-r",
    "href": "tutorials/tutorial-w01.html#why-r",
    "title": "QML tutorial - Week 1",
    "section": "",
    "text": "R can be used to analyse all sorts of data, from tabular data (also known as “spreadsheets”), textual data, geographic data and even images.\n\nThis course will focus on the analysis of tabular data, since all of the techniques relevant to this type of data also apply to the other types.\n\nThe R community is a very inclusive community and it’s easy to find help. There are several groups that promote R in minority/minoritised groups, like R-Ladies, Africa R, and Rainbow R just to mention a few.\nMoreover, R is open source and free!"
  },
  {
    "objectID": "tutorials/tutorial-w01.html#the-r-console",
    "href": "tutorials/tutorial-w01.html#the-r-console",
    "title": "QML tutorial - Week 1",
    "section": "2 The R console",
    "text": "2 The R console\n\n\n\n\n\n\nR\n\n\n\n\nR is a programming language.\nWe use programming languages to interact with computers.\nYou run commands written in a console and the task related to the command is executed.\n\n\n\nWe will begin our R journey with some basics concepts from computer science. The box above introduces you to three important concepts:\n\nProgramming languages.\nExecuting commands.\nConsole.\n\nR comes with its own console. Open now the R Console.\nIt should look like the following (there will be some aesthetic differences since you are using Windows).\n\nThe Console is an interactive interface that allows you to input commands and execute them.\nYou know you can enter a command because the prompt (&gt;) is displayed, and next to it you can see the text cursor (|) flashing.\nTry writing the following command (you will learn more about R commands below):\ncat(\"Hello!\")\nTo execute the command (aka run the command), press ENTER/RETURN on your keyboard.\nThe command cat(\"Hello!\") returns (aka outputs) in the console the text given between double quotes: Hello.\nCongratulations, you have run your first R command! This command involved a function (more on functions below): the cat() function (no feline involvement…).\nSo there are different types of R commands that you can use. In the following sections you will learn about the basic types of R commands and what they can be used for.\nYou will learn more and more commands throughout the course. You don’t have to memorise them all at once: focus on understanding what they can be useful for and if you don’t remember the details, you can always check them!"
  },
  {
    "objectID": "tutorials/tutorial-w01.html#r-basics",
    "href": "tutorials/tutorial-w01.html#r-basics",
    "title": "QML tutorial - Week 1",
    "section": "3 R basics",
    "text": "3 R basics\nIn this part of the tutorial you will learn the very basics of R.\nIf you have prior experience with programming, you should find all this familiar. If not, not to worry! Make sure you understand the concept highlighted in the green boxes and practice the related skills.\nFor this tutorial, you will just run code directly in the R Console, i.e. you will type code in the Console and press ENTER/RETURN (ENTER from now on) to run it.\nIn future tutorials, you will learn how to save your code in a script file, so that you can keep track of what you have run and make your work reproducible.\n\n3.1 R as a calculator\nWrite this line of code 1 + 2 in the Console, then press ENTER to run it.\nFantastic! You should see that the answer of the addition has been printed in the Console, like this:\n[1] 3\n(Never mind the [1] part for now).\n\n\n\n\n\n\nArithmentic operations\n\n\n\nYou can run arithmetic operations using maths operators: the most common are +, -, *, / for addition, subtraction, multiplication and division.\n\n\nNow, try some more operations (write one line and press ENTER, then write the following line and so on…). Feel free to add your own operations to the mix!\n\n67 - 13\n2 * 4\n268 / 43\n\nYou can also chain multiple operations.\n\n6 + 4 - 1 + 2\n4 * 2 + 3 * 2\n\n\n\n\n\n\n\nQuiz 2\n\n\n\nAre the following statements true of false?\n\n3 * 2 / 4 returns the same result as 3 * (2 / 4) TRUEFALSE\n10 * 2 + 5 * 0.2 returns the same result as (10 * 2 + 5) * 0.2 TRUEFALSE\n\n\n\n\n\n\n\n\n\nExtra: Arithmetics\n\n\n\n\n\nIf you need a maths refresher, I recommend checking the following pages:\n\nhttps://www.mathsisfun.com/definitions/order-of-operations.html\nhttps://www.mathsisfun.com/algebra/introduction.html\n\n\n\n\n\n\n3.2 Variables\n\nForget-me-not.\n\nMost times, we want to store a certain value so that we can use it again later.\nWe can achieve this by creating variables.\n\n\n\n\n\n\nVariable\n\n\n\nA variable holds one or more values and it’s stored in the computer memory for later use.\n\n\nYou can create a variable by using the assignment operator &lt;-.\nLet’s assign the value 156 to the variable my_num.\n\nmy_num &lt;- 156\n\n\nNow, you can just call the variable back when you need it! Write the following in the Console and press ENTER.\n\nmy_num\n\n[1] 156\n\n\nYou should see the value of my_num being printed in the console.\nA variable like my_num is called a numeric vector: i.e. a vector that contains a number (hence numeric).\n\n\n\n\n\n\nVector\n\n\n\nA vector is an R object that contains one or more values of the same type.\n\n\nA vector is a type of variable and a numeric vector is a type of vector. However, it’s fine in most cases to use the word variable to mean vector (just note that a variable can also be something else than a vector; you will learn about other R objects from next week).\nLet’s now try some operations using variables.\n\nincome &lt;- 1200\nexpenses &lt;- 500\nincome - expenses\n\n[1] 700\n\n\nSee? You can use math operators with variables too!\nAnd you can also go all the way with variables.\n\nsavings &lt;- income - expenses\n\nNow check the value of savings…\n\nsavings\n\n[1] 700\n\n\nVectors can hold more than one item or value.\nJust use the combine c() function to create a vector containing multiple values.\nThe following are all numeric vectors.\n\na &lt;- 6\n# Vector with 2 values\nb &lt;- c(6, 8)\n# Vector with 3 values\nc &lt;- c(6, 8, 42)\n\n\nYou can check the type of vector (called class in R) with the class() function: for example, class(a) returns \"numeric\".\n\nclass(a)\n\n[1] \"numeric\"\n\n\n\n\n\n\n\n\nNumeric vector\n\n\n\nA numeric vector is a vector that holds one or more numeric values.\n\n\nNote that the following are the same:\n\na &lt;- 6\na\n\n[1] 6\n\nd &lt;- c(6)\nd\n\n[1] 6\n\n\nAnother important aspect of variables is that they are… variable! Meaning that once you assign a value to one variable, you can overwrite the value by assigning a new one to the same variable.\n\nmy_num &lt;- 88\nmy_num &lt;- 63\nmy_num\n\n[1] 63\n\n\nWhat if you want to know which variables you have created so far? Easy: use the ls() function. Just write ls() in the console and press ENTER: a list of existing variables will be returned.\n\n\n\n\n\n\nQuiz 3\n\n\n\nTrue or false?\n\nA vector is a type of variable. TRUEFALSE\nNot all variables are vectors. TRUEFALSE\nA numeric vector can only hold numeric values. TRUEFALSE\n\n\n\n\n\n3.3 Functions\n\nR cannot function without… functions.\n\nWe have encountered a few functions: cat(), c(), class() and ls().\n\n\n\n\n\n\nFunction\n\n\n\nA function usually runs an operation on one or more specified arguments.\n\n\nA function in R has the form function() where:\n\nfunction is the name of the function, like cat.\n() are round parentheses, inside of which you write arguments, separated by commas.\n\nLet’s see an example with the function sum() (can you guess what it does?):\n\nsum(3, 5)\n\n[1] 8\n\n\nThe sum() function sums the numbers listed as arguments. Above, the arguments are 3 and 5.\nAnd of course arguments can be vectors!\n\nmy_nums &lt;- c(3, 5, 7)\n\nsum(my_nums)\n\n[1] 15\n\nmean(my_nums)\n\n[1] 5\n\n\nSome functions work without specifying an argument, like ls().\nYou can also nest functions one inside the other: the output of the “lowest” function is used as the argument of the function above. Try and untangle the following.\n\ny &lt;- 10\nu &lt;- 6\ni &lt;- 7\no &lt;- 2\n\ncat(mean(c(sum(y, u), sum(i, o))))\n\n12.5\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuiz 4\n\n\n\nTrue or false?\n\nYou can use functions within functions. TRUEFALSE\nAll function arguments must be specified. TRUEFALSE\nAll functions need at least one argument. TRUEFALSE\n\n\n\n\n\n\n\n\n\nExtra: R vs Python\n\n\n\n\n\nIf you are familiar with Python, you will soon realise that R and Python, although they share many concepts and types of objects, they can differ substantially. This is because R is a functional programming language (based on functions) while Python is an Object Oriented programming language (based on methods applied on objects).\nGenerally speaking, functions look like print(x) while methods look like x.print()\n\n\n\n\n\n3.4 String and logical vectors\n\nNot just numbers.\n\nWe have seen that variables can hold numeric vectors. But vectors are not restricted to being numeric. They can also store strings.\nA string is basically a set of characters (a word, a sentence, a full text).\nIn R, strings have to be quoted using double quotes \" \".\nChange the following strings to your name and surname. Remember to keep the double quotes\n\nname &lt;- \"Stefano\"\nsurname &lt;- \"Coretta\"\n\nname\n\n[1] \"Stefano\"\n\n\nStrings can be used as arguments in functions, like numbers can.\n\ncat(\"My name is\", name, surname)\n\nMy name is Stefano Coretta\n\n\nRemember that you can reuse the same variable name to override the variable value.\n\nname &lt;- \"Raj\"\n\ncat(\"My name is\", name, surname)\n\nMy name is Raj Coretta\n\n\nYou can combine multiple strings into a character vector, using c().\n\n\n\n\n\n\nCharacter vector\n\n\n\nA character vector is a vector that holds one or more strings.\n\n\n\nfruit &lt;- c(\"apple\", \"oranges\", \"bananas\")\nfruit\n\n[1] \"apple\"   \"oranges\" \"bananas\"\n\n\nUse the class() function to check the vector class.\n\nclass(fruit)\n\n[1] \"character\"\n\n\nAnother type of vector is one that contains either TRUE or FALSE. Vectors of this type are called logical vectors and their class is logical.\n\n\n\n\n\n\nLogical vector\n\n\n\nA logical vector is a vector that holds one or more TRUE or FALSE values.\n\n\n\ngroceries &lt;- c(\"apple\", \"flour\", \"margarine\", \"sugar\")\nin_pantry &lt;- c(TRUE, TRUE, FALSE, TRUE)\nclass(in_pantry)\n\n[1] \"logical\"\n\ndata.frame(groceries, in_pantry)\n\n\n\n  \n\n\n\nTRUE and FALSE values must be written in all capitals and without double quotes (they are not strings!).\n(We will talk about data frames, another type of object in R, in the following weeks.)\n\n\n\n\n\n\nQuiz 5\n\n\n\n\nWhich of the following is not a character vector.\n\n c(1, 2, \"43\") \"s\" c(apple) (assuming apple &lt;- 45) c(letters)\n\nWhich of the following is not a logical vector.\n\n c(T, T, F) TRUE \"FALSE\" c(FALSE)\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can use the class() function to check the type (“class”) of a vector.\n\nclass(FALSE)\n\n[1] \"logical\"\n\nclass(c(1, 45))\n\n[1] \"numeric\"\n\nclass(c(\"a\", \"b\"))\n\n[1] \"character\"\n\n\n\n\n\n\n\n\n\n\n\nExplanation\n\n\n\n\n\n5a\n\nc(1, 2, \"43\") is a character vector because the last number \"43\" is a string (it’s between double quotes!). A vector cannot have a mix of types of elements: they have to be all numbers or all strings or else, but not some numbers and some strings. Numbers are special in that if you include a number in a character vector without quoting it, it is automatically converted into a string. Try the following:\n\n\nchar &lt;- c(\"a\", \"b\", \"c\")\nchar &lt;- c(char, 1)\nchar\nclass(char)\n\n\nc(letters) is a character vector because letters contains the letters of the alphabet as strings (this vector comes with base R).\nc(apple) is not a character vector because the variable apple holds a number, 45!\n\n5b\n\n\"FALSE\" is not a logical vector because FALSE has been quoted (anything that is quoted is a string!).\n\n\n\n\n\n\n\n\n\n\n\n\nExtra: For-loops and if-else statements\n\n\n\n\n\nThis course does not cover programming in R in the strict sense, but if you are curious here’s a short primer on for-loops and if-else statements in R.\nFor-loops\n\nfruits &lt;- c(\"apples\", \"mangos\", \"durians\")\n\nfor (fruit in fruits) {\n  cat(\"I like\", fruit, \"\\n\")\n}\n\nI like apples \nI like mangos \nI like durians \n\n\nIf-else\n\nfor (fruit in fruits) {\n  if (grepl(\"n\", fruit)) {\n    cat(fruit, \"has an 'n'\", \"\\n\")\n  } else {\n    cat(fruit, \"does not have an 'n'\", \"\\n\")\n  }\n}\n\napples does not have an 'n' \nmangos has an 'n' \ndurians has an 'n'"
  },
  {
    "objectID": "tutorials/tutorial-w01.html#summary",
    "href": "tutorials/tutorial-w01.html#summary",
    "title": "QML tutorial - Week 1",
    "section": "4 Summary",
    "text": "4 Summary\nYou made it! You completed this week’s tutorial.\nHere’s a summary of what you learnt.\n\n\n\n\n\n\n\nR is a programming language while RStudio is an IDE.\nYou can perform mathematical operations with +, -, *, /.\nYou can store values in variables.\nA typical object to be stored in a variable is a vector: there are different type of vectors, like numeric, character and logical.\nFunctions are used to perform an operation on its arguments: sum() sums it’s arguments, mean() calculates the mean and cat() prints the arguments.\n\n\n\n\n\n\n\n\n\n\nExtra: Programming in R\n\n\n\n\n\nIf you are interested in learning about programming in R, I recommend you go through Chapters 26-28 of the R4DS book and the Advanced R book.\nNote that these topics are not covered in the course, nor will be assessed."
  },
  {
    "objectID": "tutorials/tutorial-w03.html",
    "href": "tutorials/tutorial-w03.html",
    "title": "DAL tutorial - Week 3",
    "section": "",
    "text": "In the tutorial last week you’ve been playing around with R, RStudio and R scripts.\nBut what if you want to import data in R?\nEasy! You can use the read_*() functions to read your files into R. But before we dive in, let’s first talk about some computer basics. (You can skip this section if it’s too basic for you.)\n\n\nFiles saved on your computer live in a specific place. For example, if you download a file from a browser (like Google Chrome, Safari or Firefox), the file is normally saved in the Download folder.\nBut where does the Download folder live? Usually, in your user folder! The user folder normally is the name of your account or a name you picked when you created your computer account. In my case, my user folder is simply called ste.\n\n\n\n\n\n\nUser folder\n\n\n\nThe user folder is the folder with the name of your account.\n\n\n\n\n\n\n\n\nHow to find your user folder name\n\n\n\n\n\nOn macOS\n\nOpen the Finder Preferences.\nGo to Sidebar.\nThe name next to the house icon is the name of your home folder.\n\nOn Windows\n\nRight-click an empty area on the navigation panel in File Explorer.\nFrom the context menu, select the ‘Show all folders’ and your user profile will be added as a location in the navigation bar.\n\n\n\n\nSo, let’s assume I download a file, let’s say big_data.csv, in the Download folder of my user folder.\nNow we can represent the location of the big_data.csv file like so:\nste/\n└── Downloads/\n    └── big_data.csv\nTo mark that ste and Downloads are folders, we add a final forward slash /. That simply means “hey! I am a folder!”. big_data.csv is a file, so it doesn’t have a final /.\nInstead, the file name big_data.csv has a file extension. The file extension is .csv. A file extension marks the type of file: in this the big_data file is a .csv file, a comma separated value file (we will see an example of what that looks like later).\nDifferent file type have different file extensions:\n\nExcel files: .xlsx.\nPlain text files: .txt.\nImages: .png, .jpg, .gif.\nAudio: .mp3, .wav.\nVideo: .mp4, .mov, .avi.\nEtc…\n\n\n\n\n\n\n\nFile extension\n\n\n\nA file extension is a sequence of letters that indicates the type of a file and it’s separated with a . from the file name.\n\n\n\n\n\nNow, we can use an alternative, more succinct way, to represent the location of the big_data.csv:\nste/Downloads/big_data.csv\nThis is called a file path! It’s the path through folders that lead you to the file. Folders are separated by / and the file is marked with the extension .csv.\n\n\n\n\n\n\nFile path\n\n\n\nA file path indicates the location of a file on a computer as a path through folders that lead you to the file.\n\n\nNow the million pound question: where does ste/ live on my computer???\nUser folders are located in different places depending on the operating system you are using:\n\nOn macOS: the user folder is in /Users/.\n\nYou will notice that there is a forward slash also before the name of the folder. That is because the /Users/ folder is a top folder, i.e. there are no folders further up in the hierarchy of folders.\nThis means that the full path for the big_data.csv file on a computer running macOS would be: /Users/ste/Downloads/big_data.csv.\n\nOn Windows: the user folder is in C:/Users/\n\nYou will notice that C is followed by a colon :. That is because C is a drive, which contains files and folders. C: is not contained by any other folder, i.e. there are no other folders above C: in the hierarchy of folders.\nThis means that the full path for the big_data.csv file on a Windows computer would be: C:/Users/ste/Downloads/big_data.csv.\n\n\nWhen a file path starts from a top-most folder, we call that path the absolute file path.\n\n\n\n\n\n\nAbsolute path\n\n\n\nAn absolute path is a file path that starts with a top-most folder.\n\n\nThere is another type of file paths, called relative paths. A relative path is a partial file path, relative to a specific folder. You will learn how to use relative paths below, when we will go through importing files in R using R scripts below.\nImporting files in R is very easy with the tidyverse packages. You just need to know the file type (very often the file extension helps) and the location of the file (i.e. the file path).\nThe next sections will teach you how to import data in R!\n\n\n\n\n\n\nQuiz 1\n\n\n\nWhich of the following is an absolute paths?\n\n Downloads/courses/dal/data/ /Users/smruti/Downloads/data/files/ sascha/Documents/files_pdf/paper.pdf"
  },
  {
    "objectID": "tutorials/tutorial-w03.html#some-computer-basics",
    "href": "tutorials/tutorial-w03.html#some-computer-basics",
    "title": "DAL tutorial - Week 3",
    "section": "",
    "text": "In the tutorial last week you’ve been playing around with R, RStudio and R scripts.\nBut what if you want to import data in R?\nEasy! You can use the read_*() functions to read your files into R. But before we dive in, let’s first talk about some computer basics. (You can skip this section if it’s too basic for you.)\n\n\nFiles saved on your computer live in a specific place. For example, if you download a file from a browser (like Google Chrome, Safari or Firefox), the file is normally saved in the Download folder.\nBut where does the Download folder live? Usually, in your user folder! The user folder normally is the name of your account or a name you picked when you created your computer account. In my case, my user folder is simply called ste.\n\n\n\n\n\n\nUser folder\n\n\n\nThe user folder is the folder with the name of your account.\n\n\n\n\n\n\n\n\nHow to find your user folder name\n\n\n\n\n\nOn macOS\n\nOpen the Finder Preferences.\nGo to Sidebar.\nThe name next to the house icon is the name of your home folder.\n\nOn Windows\n\nRight-click an empty area on the navigation panel in File Explorer.\nFrom the context menu, select the ‘Show all folders’ and your user profile will be added as a location in the navigation bar.\n\n\n\n\nSo, let’s assume I download a file, let’s say big_data.csv, in the Download folder of my user folder.\nNow we can represent the location of the big_data.csv file like so:\nste/\n└── Downloads/\n    └── big_data.csv\nTo mark that ste and Downloads are folders, we add a final forward slash /. That simply means “hey! I am a folder!”. big_data.csv is a file, so it doesn’t have a final /.\nInstead, the file name big_data.csv has a file extension. The file extension is .csv. A file extension marks the type of file: in this the big_data file is a .csv file, a comma separated value file (we will see an example of what that looks like later).\nDifferent file type have different file extensions:\n\nExcel files: .xlsx.\nPlain text files: .txt.\nImages: .png, .jpg, .gif.\nAudio: .mp3, .wav.\nVideo: .mp4, .mov, .avi.\nEtc…\n\n\n\n\n\n\n\nFile extension\n\n\n\nA file extension is a sequence of letters that indicates the type of a file and it’s separated with a . from the file name.\n\n\n\n\n\nNow, we can use an alternative, more succinct way, to represent the location of the big_data.csv:\nste/Downloads/big_data.csv\nThis is called a file path! It’s the path through folders that lead you to the file. Folders are separated by / and the file is marked with the extension .csv.\n\n\n\n\n\n\nFile path\n\n\n\nA file path indicates the location of a file on a computer as a path through folders that lead you to the file.\n\n\nNow the million pound question: where does ste/ live on my computer???\nUser folders are located in different places depending on the operating system you are using:\n\nOn macOS: the user folder is in /Users/.\n\nYou will notice that there is a forward slash also before the name of the folder. That is because the /Users/ folder is a top folder, i.e. there are no folders further up in the hierarchy of folders.\nThis means that the full path for the big_data.csv file on a computer running macOS would be: /Users/ste/Downloads/big_data.csv.\n\nOn Windows: the user folder is in C:/Users/\n\nYou will notice that C is followed by a colon :. That is because C is a drive, which contains files and folders. C: is not contained by any other folder, i.e. there are no other folders above C: in the hierarchy of folders.\nThis means that the full path for the big_data.csv file on a Windows computer would be: C:/Users/ste/Downloads/big_data.csv.\n\n\nWhen a file path starts from a top-most folder, we call that path the absolute file path.\n\n\n\n\n\n\nAbsolute path\n\n\n\nAn absolute path is a file path that starts with a top-most folder.\n\n\nThere is another type of file paths, called relative paths. A relative path is a partial file path, relative to a specific folder. You will learn how to use relative paths below, when we will go through importing files in R using R scripts below.\nImporting files in R is very easy with the tidyverse packages. You just need to know the file type (very often the file extension helps) and the location of the file (i.e. the file path).\nThe next sections will teach you how to import data in R!\n\n\n\n\n\n\nQuiz 1\n\n\n\nWhich of the following is an absolute paths?\n\n Downloads/courses/dal/data/ /Users/smruti/Downloads/data/files/ sascha/Documents/files_pdf/paper.pdf"
  },
  {
    "objectID": "tutorials/tutorial-w03.html#data-types",
    "href": "tutorials/tutorial-w03.html#data-types",
    "title": "DAL tutorial - Week 3",
    "section": "2 Data types",
    "text": "2 Data types\n\n2.1 Tabular data\n\n\n\n\n\n\nTabular data\n\n\n\nTabular data is data that has a form of a table: i.e. values structured in columns and rows.\n\n\nMost of the data we will be using in this course will be tabular and the files will be in the .csv format.\nThe comma separated values format (.csv) is the best format to save data in because it is basically a plain text file, it’s quick to parse, and can be opened and edited with any software (plus, it’s not a proprietary format).\nThis is what a .csv file looks like when you open it in a text editor (showing only the first few lines).\nGroup,ID,List,Target,ACC,RT,logRT,Critical_Filler,Word_Nonword,Relation_type,Branching\nL1,L1_01,A,banoshment,1,423,6.0474,Filler,Nonword,Phonological,NA\nL1,L1_01,A,unawareness,1,603,6.4019,Critical,Word,Unrelated,Left\nL1,L1_01,A,unholiness,1,739,6.6053,Critical,Word,Constituent,Left\nL1,L1_01,A,bictimize,1,510,6.2344,Filler,Nonword,Phonological,NA\nThe file contains tabular data (data that is structured as columns and rows, like a spreadsheet).\nTo separate the values of each column, a .csv file uses a comma , (hence the name “comma separated values”) to separate the values in every row.\nThe first line of the file indicates the names of the columns of the table:\nGroup,ID,List,Target,ACC,RT,logRT,Critical_Filler,Word_Nonword,Relation_type,Branching\nThere are 11 columns. The rest of the rows is the data, i.e. the values of each column separated by commas.\nL1,L1_01,A,banoshment,1,423,6.0474,Filler,Nonword,Phonological,NA\nL1,L1_01,A,unawareness,1,603,6.4019,Critical,Word,Unrelated,Left\nL1,L1_01,A,unholiness,1,739,6.6053,Critical,Word,Constituent,Left\nL1,L1_01,A,bictimize,1,510,6.2344,Filler,Nonword,Phonological,NA\nThis might look a bit confusing, but you will see later that, after importing this type of file, you can view it as a nice spreadsheet (as you would in Excel).\nAnother common type of tabular data file is spreadsheets, like spreadsheets created by Microsoft Excel or Apple Numbers. These are all proprietary formats that require you to have the software that were created with if you want to modify them.\nPortability and openness are important aspects of conducting ethical research, so that using open and non-proprietary file types makes your research more accessible and doesn’t privilege those who have access to specific software (remember, R is free!).\nThere are also variations of the comma separated values type, like tab separated values files (.tsv, which uses tab characters instead of commas) and fixed-width files (usually .txt, where columns are separated by as many white spaces as needed so that the columns align).\n\n\n2.2 Non-tabular data\nOf course, R can import also data that is not tabular, like map data and complex hierarchical data.\nWe will dip our toes in map data at the end of course, but virtually all of the data we will use will be tabular, just because that’s the format you need to do data visualisation and analyses.\n\n\n2.3 .rds files\nR has a special way of saving data: .rds files.\n.rds files allow you to save an R object to a file on your computer, so that you can read that file in when you need it.\nA common use for .rds files is to save tabular data that you have processed so that it can be readily used in many different scripts or even by other people.\nIn the following sections you will learn how to import (aka read) three types of data: .csv, Excel and .rds files."
  },
  {
    "objectID": "tutorials/tutorial-w03.html#download-the-data-files",
    "href": "tutorials/tutorial-w03.html#download-the-data-files",
    "title": "DAL tutorial - Week 3",
    "section": "3 Download the data files",
    "text": "3 Download the data files\nThroughout the course we will be using data files that come from linguistic research. You should download now the data files according to the following instructions\nPlease, follow these instructions carefully.\n\nDownload the zip archive with all the data by right-clicking on the following link and download the file: data.zip.\nUnzip the zip file to extract the contents. (If you don’t know how to do this, ask one of the tutors to help you!)\nCreate a folder called data/ (the slash is there just to remind you that it’s a folder, but you don’t have to include it in the name) in the Quarto project you are using for the course.\n\nTo create a folder, go to the Files tab of the bottom-right panel in RStudio.\nMake sure you are viewing the project’s main folder.\nClick on the New Folder button, enter “data” in the text box and click OK\n\nMove the contents of the data.zip archive into the data/ folder.\n\nOpen a Finder or File Explorer window.\nNavigate to the folder where you have extracted the zip file (it will very likely be the Downloads/ folder).\nCopy the contents of the zip file.\nIn Finder or File Explorer, navigate to the Quarto project folder, then the data/ folder, and paste the contents in there. (You can also drag and drop if you prefer.)\n\n\nThe rest of the tutorial will assume that you have created a folder called data/ in the Quarto project folder and that the files you downloaded are in that folder. The data folder should like something like this:\ndata/\n└── cameron2020/\n    └── gestures.csv\n└── coretta2018/\n    └── formants.csv\n    └── token-measures.csv\n└── ...\nI recommend that you start being very organised with your files in other projects from now on, whether it’s for this course or your dissertation or else. I also suggest to avoid overly nested structures (for example, avoid having one folder for each week for this course. Rather, save all data files in the data/ folder).\n\n\n\n\n\n\nOrganising your files\n\n\n\n\n\nThe Open Science Framework has the following recommendations that apply very well to any type of research project.\n\nUse one folder per project. This will also be your RStudio project folder.\nSeparate raw data from derived data.\nSeparate code from data.\nMake raw data read-only.\n\nTo learn more about this, check the OSF page Organising files.\nIn brief, what these recommendations mean is that you want a folder for your research project/course/else, and inside the folder two folders: one for data and one for code.\nThe data/ folder could further contain raw/ for raw data (data that should not be lost or changed, for example collected data or annotations) and derived/ for data that derives from the raw data, for example through automated data processing.\nI usually also have a separate folder called figs/ or img/ where I save plots. Of course which folders you will have it’s ultimately up to you and needs will vary depending on the project and field!"
  },
  {
    "objectID": "tutorials/tutorial-w03.html#import-.csv-files",
    "href": "tutorials/tutorial-w03.html#import-.csv-files",
    "title": "DAL tutorial - Week 3",
    "section": "4 Import .csv files",
    "text": "4 Import .csv files\nLet’s start with data from this paper: Song et al. 2020. Second language users exhibit shallow morphological processing. DOI: 10.1017/S0272263120000170.\nThe study consisted of a lexical decision task in which participants where first shown a prime, followed by a target word for which they had to indicate whether it was a real word or a nonce word.\nThe prime word belonged to one of three possible groups (Relation_type in the data) each of which refers to the morphological relation of the prime and the target word:\n\nUnrelated: for example, prolong (assuming unkindness as target, [[un-kind]-ness]).\nConstituent: unkind.\nNonConstituent: kindness.\n\n\n4.1 The tidyverse packages\nImporting .csv files is very easy. You can use the read_csv() function from a collection of R packages known as the tidyverse.\nTo import data in R we will use the read_csv() function from the readr package, one of the tidyverse packages.\nInstalling the tidyverse packages is easy: you just need to install the tidyverse package and that will take care of installing the most important packages in the collection (called the “core” tidyverse packages).\nGo ahead and install the tidyverse from the Packages tab.1\n\n\n4.2 read_csv()\nThe read_csv() function from the readr package only requires you to specify the file path as a string (remember, strings are quoted between \" \", for example \"year_data.txt\"). On my computer, the file path of song2020/shallow.csv is /Users/ste/dal/data/song2020/shallow.csv, but on your computer the file path will be different, of course.\nAlso, note that it is not enough to use the read_csv() function. You also must assign the output of the read_csv() function (i.e. the data we are reading) to a variable, using the assignment arrow &lt;-, just like we were assigning values to variables in the previous weeks.\nAnd since the read_csv() is a function from the tidyverse, you first need to attach the tidyverse packages with library(tidyverse) (remember, you need to attach packages only once per session). This will attach the core tidyverse packages, including readr. Of course, you can also attach the individual packages directly: library(readr). If you use library(tidyverse) there is no need to attach individual tidyverse packages.\nBefore reading the data, create a new R script named tutorial_w03.R and save it in the code/ folder of your Quarto project.\nGenerally, you start the script with calls to library() to load all the packages you need for the script.\nNow we only need one package, tidyverse, but in most cases you will need more than one! The best practice is to attach all of packages first, in the top of your script. Please, get in the habit of doing this from now, so that you can keep your scripts tidy and pretty!\n\n\n\n\n\n\nWarning\n\n\n\nPlease, don’t include install.packages() in your R scripts!\nRemember, you only have to install a package once, and you can just type it in the Console.\nBut DO include library() in your scripts.\n\n\nAt the top of tutorial_w03.R, write the following lines of code. Then run the code.\n\nlibrary(tidyverse)\n\nsong2020 &lt;- read_csv(\"./data/song2020/shallow.csv\")\n\nRows: 6500 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): Group, ID, List, Target, Critical_Filler, Word_Nonword, Relation_ty...\ndbl (3): ACC, RT, logRT\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nIf you look at the Environment tab, you will see song2020 under Data.\nBut wait, what is that \"./data/song2020/shallow.csv\"? That’s a relative path. We briefly mentioned relative paths above, but let’s understand the details now. You will be able to view the data soon.\n\n\n4.3 Relative paths\n\n\n\n\n\n\nRelative path\n\n\n\nA relative path is a file path that is relative to a folder, which is represented by ./\n\n\nWhen you are using R scripts in Quarto projects, the ./ folder paths are relative to is the project folder! This is true whichever the name of the folder/project and whichever it’s location on your computer.\nFor example, if your project it’s called awesome_proj and it’s in Downloads/stuff/, then if you write ./data/results.csv you really mean Downloads/stuff/awesome_proj/data/results.csv!\nHow does R know the path is relative to the project folder?\nThat is because when working with Quarto projects, all relative paths are relative to the project folder (i.e. the folder with the .Rproj file)!\nThe folder which relative paths are relative to is called the working directory (directory is just another way of saying folder).\n\n\n\n\n\n\nWorking directory\n\n\n\nThe working directory is the folder which relative paths are relative to.\nWhen using RStudio projects, the working directory is the project folder.\n\n\nThe code read_csv(\"./data/song2020/shallow.csv\") above will work because you are using an RStudio project and inside the project folder there is a folder called data/ and in it there’s the song2020/shallow.csv file.\nSo from now on I encourage you to use Quarto projects, R scripts and relative paths always!\nThe benefit of doing so is that, if you move your project or rename it, or if you share the project with somebody, all the paths will just work because they are relative!\n\n\n\n\n\n\nGet the working directory\n\n\n\n\n\nYou can get the current working directory with the getwd() command.\nRun it now in the Console! Is the returned path the project folder path?\nIf not, it might be that you are not working from a Quarto project. Check the top-right corner of RStudio: is the project name in there or do you see Project (none)?\nIf it’s the latter, you are not in a Quarto project, but you are running R from somewhere else (meaning, the working directory is somewhere else). If so, close RStudio and open the project.\n\n\n\n\n\n4.4 View the data\nNow we can finally view the data.\nThe easiest way is to click on the name of the data listed in the Environment tab, in the top-right panel of RStudio.\nYou will see a nicely formatted table, as you would in a programme like Excel.\nData tables in R (i.e. tabular, spread-sheet like data) are called data frames or tibbles.2\nThe song2020 data frame contains 11 columns (called variables in the Environment tab). The 11 columns are the following:\n\nGroup: L1 vs L2 speakers of English.\nID: Subject unique ID.\nList: Word list (A to F).\nTarget: Target word in the lexical decision trial.\nACC: Lexical decision response accuracy (0 incorrect response, 1 correct response).\nRT: Reaction times of response in milliseconds.\nlogRT: Logged reaction times.\nCritical_Filler: Whether the trial was a filler or critical.\nWord_Nonword: Whether the Target was a real Word or a Nonword.\nRelation_type: The type of relation between prime and target word (Unrelated, NonCostituent, Constituent, Phonological).\nBranching: Constituent syntactic branching, Left and Right (shout out to Charlie Puth).\n\n\n\n\n\n\n\nQuiz 3\n\n\n\nHow many rows does shallow have?\n\n 11 650 6500"
  },
  {
    "objectID": "tutorials/tutorial-w03.html#import-excel-sheets",
    "href": "tutorials/tutorial-w03.html#import-excel-sheets",
    "title": "DAL tutorial - Week 3",
    "section": "5 Import Excel sheets",
    "text": "5 Import Excel sheets\nTo read an Excel file we need first to attach the readxl package.\n\nlibrary(readxl)\n\nThen we can use the read_excel() function. Let’s read the file.\n\nlos2023 &lt;- read_excel(\"./data/los2023/relatives.xlsx\")\n\nNow you can view the tibble los2023.\nNote that if the Excel file has more than one sheet, you can specify the sheet number when reading the file (the default is sheet = 1).\n\nlos2023_2 &lt;- read_excel(\"./data/los2023/relatives.xlsx\", sheet = 2)\n\nThe second sheet in los2023.xlx contains the description of the columns in the first sheet."
  },
  {
    "objectID": "tutorials/tutorial-w03.html#import-.rds-files",
    "href": "tutorials/tutorial-w03.html#import-.rds-files",
    "title": "DAL tutorial - Week 3",
    "section": "6 Import .rds files",
    "text": "6 Import .rds files\nAnother useful type of data files is a file type specifically designed for r: .rds files.\nUsually, each .rds file contains one R object, like one tibble.\nYou can read .rds files with the readRDS() function.\n\nglot_status &lt;- readRDS(\"./data/coretta2022/glot_status.rds\")\n\nAs always, you need to assign the output of the function to a variable, here glot_status.\n\n\n\n\n\n\nRds files\n\n\n\n.Rds files are a type of R file which can store any R object and save it on disk.\nR objects can be saved to an .Rds file with the saveRDS() function and they can be read with the readRDS() function.\n\n\nView the glot_status tibble now.\nIt is also very easy to save a tibble to an .rds file with the saveRDS() function.\nFor example:\n\nsaveRDS(song2020, \"./data/song2020/shallow.rds\")\n\nThe first argument is the name of the tibble object and the second argument is the file path to save the object to."
  },
  {
    "objectID": "tutorials/tutorial-w03.html#practice",
    "href": "tutorials/tutorial-w03.html#practice",
    "title": "DAL tutorial - Week 3",
    "section": "7 Practice",
    "text": "7 Practice\n\n\n\n\n\n\nPractice 1\n\n\n\n\n\nRead the following files in R, making sure you use the right read_*() function.\n\nkoppensteiner2016/takete_maluma.txt (a tab separated file)\npankratz2021/si.csv\nGo to https://datashare.ed.ac.uk/handle/10283/4006 and download the file conflict_data_.xlsx. Read both sheets (“conflict_data2” and “demographics”). Any issues?"
  },
  {
    "objectID": "tutorials/tutorial-w03.html#summary",
    "href": "tutorials/tutorial-w03.html#summary",
    "title": "DAL tutorial - Week 3",
    "section": "8 Summary",
    "text": "8 Summary\n\n\n\n\n\n\n\nYou have learnt about directories, file extensions and file paths.\nYou can import tabular data in R with the read_*() functions from the tidyverse package readr.\nYou can view data in RStudio as spreadsheets."
  },
  {
    "objectID": "tutorials/tutorial-w03.html#footnotes",
    "href": "tutorials/tutorial-w03.html#footnotes",
    "title": "DAL tutorial - Week 3",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLab PCs should already have the tidyverse packages installed.↩︎\nA tibble is a special data frame. We will learn more about tibbles in the following weeks.↩︎"
  },
  {
    "objectID": "tutorials/tutorial-w05.html",
    "href": "tutorials/tutorial-w05.html",
    "title": "DAL tutorial - Week 5",
    "section": "",
    "text": "Data transformation is a fundamental aspect of data analysis.\nAfter the data you need to use is imported into R, you will have to filter rows, create new columns, or join data frames, among many other transformation operations.\nIn this tutorial we will learn how to filter() the data and mutate() or create new columns. In Week 6 (after Flexible Learning week) you will learn how to obtain summary measures and how to count occurrences using the summarise(), group_by() and count() functions."
  },
  {
    "objectID": "tutorials/tutorial-w05.html#data-transformation",
    "href": "tutorials/tutorial-w05.html#data-transformation",
    "title": "DAL tutorial - Week 5",
    "section": "",
    "text": "Data transformation is a fundamental aspect of data analysis.\nAfter the data you need to use is imported into R, you will have to filter rows, create new columns, or join data frames, among many other transformation operations.\nIn this tutorial we will learn how to filter() the data and mutate() or create new columns. In Week 6 (after Flexible Learning week) you will learn how to obtain summary measures and how to count occurrences using the summarise(), group_by() and count() functions."
  },
  {
    "objectID": "tutorials/tutorial-w05.html#filter",
    "href": "tutorials/tutorial-w05.html#filter",
    "title": "DAL tutorial - Week 5",
    "section": "2 Filter",
    "text": "2 Filter\nFiltering data based on specific criteria couldn’t be easier with filter(), from the dplyr package (one of the tidyverse core packages),\nLet’s work with the coretta2022/glot_status data frame. It’s an .rds file, so you need to use the readRDS() function. Go ahead and read the data into glot_status.\nThe glot_status data frame contains the endangerment status for 7,845 languages from Glottolog. There are thousands of languages in the world, but most of them are losing speakers, and some are already no longer spoken. The endangerment status of a language in the data is on a scale from not endangered (languages with large populations of speakers) through threatened, shifting and nearly extinct, to extinct (languages that have no living speakers left).\n\nglot_status\n\n\n\n  \n\n\n\nBefore we can move on onto filtering data, we first need to learn about logical operators.\n\n2.1 Logical operators\nThere are four main logical operators:\n\nx == y: x equals y.\nx != y: x is not equal to y.\nx &gt; y: x is greater than y.\nx &lt; y: x is smaller than y.\n\nLogical operators return TRUE or FALSE depending on whether the statement they convey is true or false. Remember, TRUE and FALSE are logical values.\nTry these out in the Console:\n\n# This will return FALSE\n1 == 2\n\n[1] FALSE\n\n# FALSE\n\"apples\" == \"oranges\"\n\n[1] FALSE\n\n# TRUE\n10 &gt; 5\n\n[1] TRUE\n\n# FALSE\n10 &gt; 15\n\n[1] FALSE\n\n# TRUE\n3 &lt; 4\n\n[1] TRUE\n\n\n\n\n\n\n\n\nLogical operators\n\n\n\nLogical operators are symbols that compare two objects and return either TRUE or FALSE.\nThe most common logical operators are ==, !=, &gt;, and &lt;.\n\n\n\n\n\n\n\n\nQuiz 2\n\n\n\n\nWhich of the following does not contain a logical operator?\n\n 3 &gt; 1 \"a\" = \"a\" \"b\" != \"b\" 19 &lt; 2\n\nWhich of the following returns c(FALSE, TRUE)?\n\n 3 &gt; c(1, 5) c(\"a\", \"b\") != c(\"a\") \"apple\" != \"apple\"\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\n2a.\nCheck for errors in the logical operators.\n2b.\nRun them in the console to see the output.\n\n\n\n\n\n\n\n\n\nExplanation\n\n\n\n\n\n2a.\nThe logical operator == has TWO equal signs. A single equal sign = is an alternative way of writing the assignment operator &lt;-, so that a = 1 and a &lt;- 1 are equivalent.\n2b.\nLogical operators are “vectorised” (you will learn more about this below), i.e they are applied sequentially to all elements in pairs. If the number of elements on one side does not match than of the other side of the operator, the elements on the side that has the smaller number of elements will be recycled.\n\n\n\n\n\nNow let’s see how these work with filter()!\n\n\n2.2 The filter() function\nFiltering in R with the tidyverse is straightforward. You can use the filter() function.\nfilter() takes one or more statements with logical operators.\nLet’s try this out. The following code filters the status column so that only the extinct status is included in the new data frame extinct.\nYou’ll notice we are using the pipe |&gt; to transfer the data into the filter() function; the output of the filter function is assigned &lt;- to extinct. The flow might seem a bit counter-intuitive but you will get used to think like this when writing R code soon enough!\n\nextinct &lt;- glot_status |&gt;\n  filter(status == \"extinct\")\n\nextinct\n\n\n\n  \n\n\n\nNeat! What if we want to include all statuses except extinct? Easy, we use the non-equal operator !=.\n\nnot_extinct &lt;- glot_status |&gt;\n  filter(status != \"extinct\")\n\nnot_extinct\n\n\n\n  \n\n\n\nAnd if we want only non-extinct languages from South America? We can include multiple statements separated by a comma!\n\nsouth_america &lt;- glot_status |&gt;\n  filter(status != \"extinct\", Macroarea == \"South America\")\n\nsouth_america\n\n\n\n  \n\n\n\nCombining statements like this will give you only those rows where both conditions apply. You can add as many statements as you need.\nNow try to filter the data so that you include only not_endangered languages from all macro-areas except Eurasia. This time, don’t save the output to a new data frame. What happens? Where is the output shown?\n\nglot_status |&gt;\n  filter(...)\n\nThis is all great, but what if we want to include more than one status or macro-area?\nTo do that we need another operator: %in%.\n\n\n2.3 The %in% operator\n\n\n\n\n\n\n%in%\n\n\n\nThe %in% operator is a special logical operator that returns TRUE if the value to the left of the operator is one of the values in the vector to its right, and FALSE if not.\n\n\nTry these in the Console:\n\n# TRUE\n5 %in% c(1, 2, 5, 7)\n\n[1] TRUE\n\n# FALSE\n\"apples\" %in% c(\"oranges\", \"bananas\")\n\n[1] FALSE\n\n\nBut %in% is even more powerful because the value on the left does not have to be a single value, but it can also be a vector! We say %in% is vectorised because it can work with vectors (most functions and operators in R are vectorised).\n\n# TRUE, TRUE\nc(1, 5) %in% c(4, 1, 7, 5, 8)\n\n[1] TRUE TRUE\n\nstocked &lt;- c(\"durian\", \"bananas\", \"grapes\")\nneeded &lt;- c(\"durian\", \"apples\")\n\n# TRUE, FALSE\nneeded %in% stocked\n\n[1]  TRUE FALSE\n\n\nTry to understand what is going on in the code above before moving on.\n\n\n2.4 Now filter the data\nNow we can filter glot_status to include only the macro-areas of the Global South and only languages that are either “threatened”, “shifting”, “moribund” or “nearly_extinct”. I have started the code for you, you just need to write the line for filtering status.\n\nglobal_south &lt;- glot_status |&gt;\n  filter(\n    Macroarea %in% c(\"Africa\", \"Australia\", \"Papunesia\", \"South America\"),\n    ...\n  )\n\nThis should not look too alien! The first statement, consonant %in% c(\"p\", \"t\", \"k\") looks at the consonant column and, for each row, it returns TRUE if the current row value is in c(\"p\", \"t\", \"k\"), and FALSE if not."
  },
  {
    "objectID": "tutorials/tutorial-w05.html#bar-charts",
    "href": "tutorials/tutorial-w05.html#bar-charts",
    "title": "DAL tutorial - Week 5",
    "section": "3 Bar charts",
    "text": "3 Bar charts\n\n\n\n\n\n\nBar charts\n\n\n\nBar charts are useful when you are counting things. For example:\n\nNumber of verbs vs nouns vs adjectives in a corpus.\nNumber of languages by geographic area.\nNumber of correct vs incorrect responses.\n\nThe bar chart geometry is geom_bar().\n\n\nWe will first create a plot with counts of the number of languages in global_south by their endangerment status and then a plot where we also split the counts by macro-area.\n\n3.1 Number of languages of the Global South by status\nTo create a bar chart, you can use the geom_bar() geometry.\n\n\n\n\n\n\nBar chart axes\n\n\n\nIn a simple bar chart, you only need to specify one axis, the x-axis, in the aesthetics aes().\nThis is because the counts that are placed on the y-axis are calculated by the geom_bar() function under the hood.\nThis quirk is something that confuses many new learners, so make sure you internalise this.\n\n\nGo ahead and complete the following code to create a bar chart.\n\nglobal_south |&gt;\n  ggplot(aes(x = status)) +\n  ...\n\nNote how we’re using |&gt; to pipe the glot_status data frame into the ggplot() function. This works because ggplot()’s first argument is the data, and piping is a different way of providing the first argument to a function.\nAs mentioned above, the counting for the y-axis is done automatically. R looks in the status column and counts how many times each value in the column occurs in the data frame.\nIf you did things correctly, you should get the following plot.\n\n\n\n\n\nThe x-axis is now status and the y-axis corresponds to the number of languages by status (count). As mentioned above, count is calculated under the hood for you (you will learn how to count levels with count() later in the course).\nYou could write a description of the plot that goes like this:\n\nThe number of languages in the Global South by endangered status is shown as a bar chart in Figure 1. Among the languages that are endangered, the majority are threatened or shifting.\n\nWhat if we want to show the number of languages by endangerment status within each of the macro-areas that make up the Global South? Easy! You can make a stacked bar chart, but we will get to that after we first learn about mutate()."
  },
  {
    "objectID": "tutorials/tutorial-w05.html#mutate",
    "href": "tutorials/tutorial-w05.html#mutate",
    "title": "DAL tutorial - Week 5",
    "section": "4 Mutate",
    "text": "4 Mutate\nTo change existing columns or create new columns, we can use the mutate() function from the dplyr package.\nTo learn how to use mutate(), we will re-create the status column (let’s call it Status this time) from the Code_ID column in glot_status.\nThe Code_ID column contains the status of each language in the form aes-STATUS where STATUS is one of not_endangered, threatened, shifting, moribund, nearly_extinct and extinct.\n\n\n[1] \"aes-shifting\"       \"aes-extinct\"        \"aes-moribund\"      \n[4] \"aes-nearly_extinct\" \"aes-threatened\"     \"aes-not_endangered\"\n\n\nWe want to create a new column called Status which has only the STATUS label (without the aes- part). To remove aes- from the Code_ID column we can use the str_remove() function from the stringr package. Check the documentation of ?str_remove to learn which arguments it uses.\n\nglot_status &lt;- glot_status |&gt;\n  mutate(\n    Status = str_remove(Code_ID, \"aes-\")\n  )\n\nIf you check glot_status now you will find that a new column, Status, has been added. This column is a character column (chr).\nLet’s reproduce the bar chart from above but with all the data from glot_status, using now the Status column.\n\nglot_status |&gt;\n  ggplot(aes(x = Status)) +\n  geom_bar()\n\n\n\n\nBut something is not quite right… The order of the levels of Status does not match the order that makes sense (from least to most endangered)! Why?\nThis is because status (the pre-existing column) is a factor column, rather than a simple character column. What is a factor vector/column?\n\n\n\n\n\n\nFactor vector\n\n\n\nA factor vector (or column) is a vector that contains a list of values (called levels) from a closed set.\nThe levels of a factor are ordered alphabetically by default.\n\n\nA vector/column can be mutated into a factor column with the as.factor() function. In the following code, we change the existing column Status, in other words we overwrite it (this happens automatically, because the Status column already exists, so it is replaced).\n\nglot_status &lt;- glot_status |&gt;\n  mutate(\n    Status = as.factor(Status)\n  )\n\n# read below for an expanation of the dollar disgn $ syntax\nlevels(glot_status$Status)\n\n[1] \"extinct\"        \"moribund\"       \"nearly_extinct\" \"not_endangered\"\n[5] \"shifting\"       \"threatened\"    \n\n\nThe levels() functions returns the levels of a factor column in the order they are stored in the factor: by default the order is alphabetical. But wait, what is that $ in glot_status$Status?\nThe dollar sign $ a base R way of extracting a single column (in this case Status) from a data frame (glot_status).\n\n\n\n\n\n\nThe dollar sign `$`\n\n\n\nYou can use the dollar sign $ to extract a single column from a data frame as a vector.\n\n\nWhat if we want the levels of Status to be ordered in a more logical manner: not_endangered, threatened, shifting, moribund, nearly_extinct and extinct? Easy! We can use the factor() function instead of as.factor() and specify the levels and their order.\n\nglot_status &lt;- glot_status |&gt;\n  mutate(\n    Status = factor(Status, levels = c(\"not_endangered\", \"threatened\", \"shifting\", \"moribund\", \"nearly_extinct\", \"extinct\"))\n  )\n\nlevels(glot_status$Status)\n\n[1] \"not_endangered\" \"threatened\"     \"shifting\"       \"moribund\"      \n[5] \"nearly_extinct\" \"extinct\"       \n\n\nYou see that now the order of the levels returned by levels() is the one we specified.\nTransforming character columns to vector columns is helpful to specify a particular order of the levels which can then be used when plotting.\n\nglot_status |&gt;\n  ggplot(aes(x = Status)) +\n  geom_bar()"
  },
  {
    "objectID": "tutorials/tutorial-w05.html#stacked-bar-charts",
    "href": "tutorials/tutorial-w05.html#stacked-bar-charts",
    "title": "DAL tutorial - Week 5",
    "section": "5 Stacked bar charts",
    "text": "5 Stacked bar charts\nA special type of bar charts are the so-called stacked bar charts.\n\n\n\n\n\n\nStacked bar chart\n\n\n\nA stacked bar chart is a bar chart in which each contains a “stack” of shorter bars, each indicating the counts of some sub-groups.\nThis type of plot is useful to show how counts of something vary depending on some other grouping (in other words, when you want to count the occurrences of a categorical variable based on another categorical variable). For example:\n\nNumber of languages by endangerment status, grouped by geographic area.\nNumber of infants by head-turning preference, grouped by first language.\nNumber of past vs non-past verbs, grouped by verb class.\n\n\n\nTo create a stacked bar chart, you just need to add a new aesthetic mapping to aes(): fill. The fill aesthetic lets you fill bars or areas with different colours depending on the values of a specified column.\nLet’s make a plot on language endangerment by macro-area.\nComplete the following code by specifying that fill should be based on status.\n\nglobal_south |&gt;\n  ggplot(aes(x = Macroarea, ...)) +\n  geom_bar()\n\nYou should get the following.\n\n\n\n\n\nA write-up example:\n\nFigure 3 shows the number of languages by geographic macro-area, subdivided by endangerment status. Africa, Eurasia and Papunesia have substantially more languages than the other areas.\n\n\n\n\n\n\n\nQuiz 4\n\n\n\nWhat is wrong in the following code?\ngestures |&gt;\n  ggplot(aes(x = status), fill = Macroarea) +\n  geom_bar()\n\n\nIn the plot above it is difficult to assess whether different macro-areas have different proportions of endangerment. This is because the overall number of languages per area differs between areas.\nA solution to this is to plot proportions instead of raw counts.\nYou could calculate the proportions yourself, but there is a quicker way: using the position argument in geom_bar().\nYou can plot proportions instead of counts by setting position = \"fill\" inside geom_bar(), like so:\n\n\n\n\n\nThe plot now shows proportions of languages by endangerment status for each area separately. (Note that the y-axis label is still “count” but it is in fact proportions; you will learn how to change labels next week).\nWith this plot it is easier to see that different areas have different proportions of endangerment. In writing:\n\nFigure 4 shows proportions of languages by endangerment status for each macro-area. Australia, South and North America have a substantially higher proportion of extinct languages than the other areas. These areas also have a higher proportion of near extinct languages. On the other hand, Africa has the greatest proportion of non-endangered languages followed by Papunesia and Eurasia, while North and South America are among the areas with the lower proportion, together with Australia which has the lowest."
  }
]